{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv3D, Flatten,MaxPooling3D,AveragePooling3D, concatenate,Input ,SpatialDropout3D,Dropout\n",
    "import keras\n",
    "from math import e\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump, load\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Orography\n",
    "OroData = xr.open_dataset('../../../Data/eraDown/ERA5_2degree_Down/DailyMean/ERA5IGP_Orography.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Surface data\n",
    "t2mData = xr.open_dataset('../../../Data/CMIP6/IPSL-CM6A-LR/NDJF/Regrid_NH_tas_NDJFday_IPSL-CM6A-LR_historical_r1i1p1f1_gr_18500101-20141231.nc')\n",
    "rhData  = xr.open_dataset('../../../Data/CMIP6/IPSL-CM6A-LR/NDJF/Regrid_NH_hurs_NDJFday_IPSL-CM6A-LR_historical_r1i1p1f1_gr_18500101-20141231.nc')\n",
    "u10Data = xr.open_dataset('../../../Data/CMIP6/IPSL-CM6A-LR/NDJF/Regrid_NH_uas_NDJFday_IPSL-CM6A-LR_historical_r1i1p1f1_gr_18500101-20141231.nc')\n",
    "v10Data = xr.open_dataset('../../../Data/CMIP6/IPSL-CM6A-LR/NDJF/Regrid_NH_vas_NDJFday_IPSL-CM6A-LR_historical_r1i1p1f1_gr_18500101-20141231.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level Data\n",
    "tLevData = xr.open_dataset('../../../Data/CMIP6/IPSL-CM6A-LR/NDJF/Regrid_NH_ta_NDJFday_IPSL-CM6A-LR_historical_r1i1p1f1_gr_18500101-20141231.nc')\n",
    "zLevData = xr.open_dataset('../../../Data/CMIP6/IPSL-CM6A-LR/NDJF/Regrid_NH_zg_NDJFday_IPSL-CM6A-LR_historical_r1i1p1f1_gr_18500101-20141231.nc')\n",
    "wLevData = xr.open_dataset('../../../Data/CMIP6/IPSL-CM6A-LR/NDJF/Regrid_NH_wap_NDJFday_IPSL-CM6A-LR_historical_r1i1p1f1_gr_18500101-20141231.nc')\n",
    "uLevData = xr.open_dataset('../../../Data/CMIP6/IPSL-CM6A-LR/NDJF/Regrid_NH_ua_NDJFday_IPSL-CM6A-LR_historical_r1i1p1f1_gr_18500101-20141231.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate wind speed and relative humidity inv  ushear\n",
    "ws = ((v10Data.vas.values**2)+(u10Data.uas.values**2))**0.5\n",
    "ws_ds = xr.Dataset({'ws': (('time','latitude','longitude'), ws)},\n",
    "                   coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "\n",
    "rh_ds = xr.Dataset({'rh': (('time','latitude','longitude'), rhData.hurs/100.0)},\n",
    "                   coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "\n",
    "#Calculate inv\n",
    "inv=t2mData.tas.values-tLevData.ta.sel(plev=85000,method='nearest').values\n",
    "inv_ds = xr.Dataset({'inv': (('time','latitude','longitude'), inv)}, coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "inv_ds.attrs\n",
    "inv_ds.attrs['units']='K'\n",
    "inv_ds.attrs['long_name']='t2m - t850'\n",
    "\n",
    "#u shear calculation\n",
    "ushear=(uLevData.ua.sel(plev=85000,method='nearest').values-u10Data.uas.values)/(zLevData.zg.sel(plev=85000,method='nearest').values) \n",
    "ushear_ds = xr.Dataset({'ushear': (('time','latitude','longitude'), ushear)}, coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "ushear_ds.attrs['units']='s-1'\n",
    "ushear_ds.attrs['long_name']='(u10 - u850)/z850'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AO data\n",
    "AOData = xr.open_dataset('IPSL-CM6A-LR-AOindex-NDJF-Daily-1980-2014.nc')\n",
    "aoTS=AOData.AO\n",
    "#datetimeindex = aoTS.indexes['time'].to_datetimeindex()\n",
    "#datetimeindex\n",
    "#aoTS['time'] = datetimeindex\n",
    "Darray=np.zeros((AOData.time.shape[0],t2mData.latitude.shape[0], t2mData.longitude.shape[0]))\n",
    "for t in range(aoTS.time.shape[0]) :\n",
    "    Darray[t,:,:]=np.full((t2mData.latitude.shape[0], t2mData.longitude.shape[0]), aoTS[t].values)\n",
    "AOData=xr.Dataset({'AO': (('time','latitude','longitude'), Darray)},\n",
    "                  coords={'time': aoTS.time,'latitude': t2mData.latitude,'longitude': t2mData.longitude}) \n",
    "# EU data\n",
    "EUData = xr.open_dataset('IPSL-CM6A-LR-EUindex-NDJF-Daily-1980-2014.nc')\n",
    "EUData.EU\n",
    "euTS=EUData.EU\n",
    "#datetimeindex = euTS.indexes['time'].to_datetimeindex()\n",
    "#datetimeindex\n",
    "#euTS['time'] = datetimeindex\n",
    "Darray=np.zeros((EUData.time.shape[0],t2mData.latitude.shape[0], t2mData.longitude.shape[0]))\n",
    "for t in range(euTS.time.shape[0]) :\n",
    "    Darray[t,:,:]=np.full((t2mData.latitude.shape[0], t2mData.longitude.shape[0]), euTS[t].values)\n",
    "EUData=xr.Dataset({'EU': (('time','latitude','longitude'), Darray)},\n",
    "                  coords={'time': euTS.time,'latitude': t2mData.latitude,'longitude': t2mData.longitude})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask\n",
    "oro = OroData.z.sel(latitude=slice(35,0),longitude=slice(50,100))\n",
    "oro.values = OroData.z.sel(latitude=slice(35,0),longitude=slice(50,100)).values/9.81\n",
    "oro.attrs\n",
    "oro.attrs['units']='meter'\n",
    "oro.attrs['long_name']='Orography'\n",
    "oro.values[oro.values>500.1]=np.NaN\n",
    "mask=oro.values/oro.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AO\n",
    "AO5D=AOData.AO.rolling(time=5).mean()\n",
    "\n",
    "AO5DAll=AO5D[((AO5D.time.dt.month>11) | (AO5D.time.dt.month<2)) & \n",
    "             (AO5D.time.dt.year<2020)].sel(time=slice('1980-1-1','2014-12-31'),latitude=slice(35,0),\n",
    "                                           longitude=slice(50,100))\n",
    "\n",
    "#EU\n",
    "EU5D=EUData.EU.rolling(time=5).mean()\n",
    "\n",
    "EU5DAll=EU5D[((EU5D.time.dt.month>11) | (EU5D.time.dt.month<2)) & \n",
    "             (EU5D.time.dt.year<2020)].sel(time=slice('1980-1-1','2014-12-31'),latitude=slice(35,0),\n",
    "                                           longitude=slice(50,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=AO5DAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "# fit scaler on training data\n",
    "AO5DnormIpslCm6aLr = StandardScaler().fit(t1)\n",
    "dump(AO5DnormIpslCm6aLr,'AO5DnormIpslCm6aLr.joblib')\n",
    "# transform training data\n",
    "t1.values = AO5DnormIpslCm6aLr.transform(t1)\n",
    "AO5DAll.values=t1.unstack()\n",
    "\n",
    "t1=EU5DAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "# fit scaler on training data\n",
    "EU5DnormIpslCm6aLr = StandardScaler().fit(t1)\n",
    "dump(EU5DnormIpslCm6aLr,'EU5DnormIpslCm6aLr.joblib')\n",
    "# transform training data\n",
    "t1.values = EU5DnormIpslCm6aLr.transform(t1)\n",
    "EU5DAll.values=t1.unstack()\n",
    "\n",
    "AO5DAll.values=AO5DAll.values*mask\n",
    "AO5DAll.values=xr.where(np.isnan(AO5DAll.values),  0.000000000001,AO5DAll.values)\n",
    "\n",
    "EU5DAll.values=EU5DAll.values*mask\n",
    "EU5DAll.values=xr.where(np.isnan(EU5DAll.values),  0.000000000001,EU5DAll.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m=t2mData.tas.shift(time=1)\n",
    "ws=ws_ds.ws.shift(time=1)\n",
    "rh=rh_ds.rh.shift(time=1)\n",
    "inv=inv_ds.inv.shift(time=1)\n",
    "w=wLevData.wap.sel(plev=70000,method='nearest').shift(time=1)\n",
    "ushear=ushear_ds.ushear.shift(time=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "datetimeindex = t2m.indexes['time'].to_datetimeindex()\n",
    "t2m['time'] = datetimeindex\n",
    "ws['time'] = datetimeindex\n",
    "rh['time'] = datetimeindex\n",
    "inv['time'] = datetimeindex\n",
    "w['time'] = datetimeindex\n",
    "ushear['time'] = datetimeindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2mTsAll=t2m[((t2m.time.dt.month>11) | (t2m.time.dt.month<2)) & (t2m.time.dt.year<2020)].sel(time=slice('1980-1-1','2014-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "wsTsAll=ws[((ws.time.dt.month>11) | (ws.time.dt.month<2)) & (ws.time.dt.year<2020)].sel(time=slice('1980-1-1','2014-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "rhTsAll=rh[((rh.time.dt.month>11) | (rh.time.dt.month<2)) & (rh.time.dt.year<2020)].sel(time=slice('1980-1-1','2014-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "invTsAll=inv[((inv.time.dt.month>11) | (inv.time.dt.month<2)) & (inv.time.dt.year<2020)].sel(time=slice('1980-1-1','2014-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "ushearTsAll=ushear[((ushear.time.dt.month>11) | (ushear.time.dt.month<2)) & (ushear.time.dt.year<2020)].sel(time=slice('1980-1-1','2014-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "wTsAll=w[((w.time.dt.month>11) | (w.time.dt.month<2)) & (w.time.dt.year<2020)].sel(time=slice('1980-1-1','2014-12-31'),latitude=slice(35,0),longitude=slice(50,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cccr/diptih/anaconda3/lib/python3.8/site-packages/sklearn/utils/extmath.py:847: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/cccr/diptih/anaconda3/lib/python3.8/site-packages/sklearn/utils/extmath.py:687: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs, dtype=np.float64)\n",
      "/home/cccr/diptih/anaconda3/lib/python3.8/site-packages/sklearn/utils/extmath.py:847: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/cccr/diptih/anaconda3/lib/python3.8/site-packages/sklearn/utils/extmath.py:687: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs, dtype=np.float64)\n",
      "/home/cccr/diptih/anaconda3/lib/python3.8/site-packages/sklearn/utils/extmath.py:847: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/cccr/diptih/anaconda3/lib/python3.8/site-packages/sklearn/utils/extmath.py:687: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs, dtype=np.float64)\n"
     ]
    }
   ],
   "source": [
    "t1=t2mTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "# fit scaler on training data\n",
    "t2mnormIpslCm6aLr = StandardScaler().fit(t1)\n",
    "dump(t2mnormIpslCm6aLr,'t2mnormIpslCm6aLr.joblib')\n",
    "# transform training data\n",
    "t1.values = t2mnormIpslCm6aLr.transform(t1)\n",
    "t2mTsAll.values=t1.unstack()\n",
    "\n",
    "t1=wsTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "# fit scaler on training data\n",
    "wsnormIpslCm6aLr = StandardScaler().fit(t1)\n",
    "dump(wsnormIpslCm6aLr,'wsnormIpslCm6aLr.joblib')\n",
    "# transform training data\n",
    "t1.values = wsnormIpslCm6aLr.transform(t1)\n",
    "wsTsAll.values=t1.unstack()\n",
    "\n",
    "t1=rhTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "# fit scaler on training data\n",
    "rhnormIpslCm6aLr = StandardScaler().fit(t1)\n",
    "dump(rhnormIpslCm6aLr,'rhnormIpslCm6aLr.joblib')\n",
    "# transform training data\n",
    "t1.values = rhnormIpslCm6aLr.transform(t1)\n",
    "rhTsAll.values=t1.unstack()\n",
    "\n",
    "t1=invTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "# fit scaler on training data\n",
    "invnormIpslCm6aLr = StandardScaler().fit(t1)\n",
    "dump(invnormIpslCm6aLr,'invnormIpslCm6aLr.joblib')\n",
    "# transform training data\n",
    "t1.values = invnormIpslCm6aLr.transform(t1)\n",
    "invTsAll.values=t1.unstack()\n",
    "\n",
    "t1=ushearTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "# fit scaler on training data\n",
    "ushearnormIpslCm6aLr = StandardScaler().fit(t1)\n",
    "dump(ushearnormIpslCm6aLr,'ushearnormIpslCm6aLr.joblib')\n",
    "# transform training data\n",
    "t1.values = ushearnormIpslCm6aLr.transform(t1)\n",
    "ushearTsAll.values=t1.unstack()\n",
    "\n",
    "\n",
    "t1=wTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "# fit scaler on training data\n",
    "wnormIpslCm6aLr = StandardScaler().fit(t1)\n",
    "dump(wnormIpslCm6aLr,'wnormIpslCm6aLr.joblib')\n",
    "# transform training data\n",
    "t1.values = wnormIpslCm6aLr.transform(t1)\n",
    "wTsAll.values=t1.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2mTsAll.values=t2mTsAll.values*mask\n",
    "wsTsAll.values=wsTsAll.values*mask\n",
    "rhTsAll.values=rhTsAll.values*mask\n",
    "invTsAll.values=invTsAll.values*mask\n",
    "ushearTsAll.values=ushearTsAll.values*mask\n",
    "wTsAll.values=wTsAll.values*mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2mTsAll.values=xr.where(np.isnan(t2mTsAll.values),  0.000000000001,t2mTsAll.values)\n",
    "wsTsAll.values=xr.where(np.isnan(wsTsAll.values),  0.000000000001,wsTsAll.values)\n",
    "rhTsAll.values=xr.where(np.isnan(rhTsAll.values),  0.000000000001,rhTsAll.values)\n",
    "invTsAll.values=xr.where(np.isnan(invTsAll.values),  0.000000000001,invTsAll.values)\n",
    "ushearTsAll.values=xr.where(np.isnan(ushearTsAll.values),  0.000000000001,ushearTsAll.values)\n",
    "wTsAll.values=xr.where(np.isnan(wTsAll.values),  0.000000000001,wTsAll.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2170, 18, 26, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2mt=t2mTsAll.values\n",
    "t2mt=t2mt[:,:,:,None]\n",
    "t2mt.shape\n",
    "\n",
    "\n",
    "wst=wsTsAll.values\n",
    "wst=wst[:,:,:,None]\n",
    "wst.shape\n",
    "\n",
    "rht=rhTsAll.values\n",
    "rht=rht[:,:,:,None]\n",
    "rht.shape\n",
    "\n",
    "\n",
    "invt=invTsAll.values\n",
    "invt=invt[:,:,:,None]\n",
    "invt.shape\n",
    "\n",
    "wt=wTsAll.values\n",
    "wt=wt[:,:,:,None]\n",
    "wt.shape\n",
    "\n",
    "usheart=ushearTsAll.values\n",
    "usheart=usheart[:,:,:,None]\n",
    "usheart.shape\n",
    "\n",
    "aot=AO5DAll.values\n",
    "aot=aot[:,:,:,None]\n",
    "aot.shape\n",
    "\n",
    "eut=EU5DAll.values\n",
    "eut=eut[:,:,:,None]\n",
    "eut.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2170, 18, 26, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array([t2mt,rht,wst,invt,wt,usheart,aot,eut])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2170, 8, 18, 26, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reshape = np.einsum('lkija->klija',X)\n",
    "X_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 8, 18, 26, 16)     448       \n",
      "_________________________________________________________________\n",
      "average_pooling3d (AveragePo (None, 4, 9, 13, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 4, 9, 13, 32)      13856     \n",
      "_________________________________________________________________\n",
      "average_pooling3d_1 (Average (None, 2, 5, 7, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2, 5, 7, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 2, 5, 7, 64)       55360     \n",
      "_________________________________________________________________\n",
      "average_pooling3d_2 (Average (None, 1, 3, 4, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 3, 4, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                24608     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 94,305\n",
      "Trainable params: 94,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load saved model\n",
    "# load model\n",
    "model = load_model('../../March2021/Observation_models/modelCNN.h5')\n",
    "# summarize model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "yLR=model.predict(X_reshape)\n",
    "y_predLin_ds=xr.Dataset({'yLR': (('time'), yLR[:,0])}, coords={'time':t2mTsAll.time.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Model_plots/IPSL-CM6A-LR-CNN-Y1.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dump(y_predLin_ds.yLR,'../Model_plots/IPSL-CM6A-LR-CNN-Y.joblib')\n",
    "dump(y_predLin_ds.yLR,'../Model_plots/IPSL-CM6A-LR-CNN-Y1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
