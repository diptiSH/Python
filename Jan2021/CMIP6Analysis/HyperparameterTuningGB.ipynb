{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "import glob\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math as mt\n",
    "\n",
    "from math import e\n",
    "\n",
    "import datetime\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import seed\n",
    "from random import randint\n",
    "\n",
    "from scipy.signal import hilbert\n",
    "import statistics\n",
    "from scipy.stats import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.ticker as ticker\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "from time import time\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fogData = xr.open_dataset('../../../Data/FogData/CombinedFogData_25Stations.nc')\n",
    "#plt.figure(figsize=[16,8])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StackFog=fogData.fogdata.stack(a=('years','months','days'))\n",
    "StackFog\n",
    "dd =[];\n",
    "for i in range(StackFog.years.values.shape[0]):\n",
    "    dd=dd+[str(StackFog.years[i].values)+'-'+str(StackFog.months[i].values)+\"-\"+str(StackFog.days[i].values)]\n",
    "fg = xr.Dataset({'fogdata': (('time','stations'), StackFog.values.T)}, coords={'time': pd.to_datetime(dd),'stations': fogData.stations})\n",
    "# fogData.fogdata.values.shape\n",
    "# fogData.stations\n",
    "#plt.figure(figsize=[16,8])\n",
    "#fg.fogdata.resample(time=\"1y\").sum().sum(dim='stations').plot()\n",
    "#fg.fogdata.time    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2mData = xr.open_dataset('../../../Data/IGPERA5/DailyFiles/DailyERA5IGP_t2m_3hourly_NovDecJan.nc')\n",
    "u10Data = xr.open_dataset('../../../Data/IGPERA5/DailyFiles/DailyERA5IGP_u10_3hourly_NovDecJan.nc')\n",
    "v10Data = xr.open_dataset('../../../Data/IGPERA5/DailyFiles/DailyERA5IGP_v10_3hourly_NovDecJan.nc')\n",
    "d2mData = xr.open_dataset('../../../Data/IGPERA5/DailyFiles/DailyERA5IGP_d2m_3hourly_NovDecJan.nc')\n",
    "t2mD = t2mData.sel(latitude=slice(32,24),longitude=slice(74,86))\n",
    "u10D = u10Data.sel(latitude=slice(32,24),longitude=slice(74,86))\n",
    "v10D = v10Data.sel(latitude=slice(32,24),longitude=slice(74,86))\n",
    "d2mD = d2mData.sel(latitude=slice(32,24),longitude=slice(74,86))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate wind speed and relative humidity\n",
    "\n",
    "ws = ((v10D.v10[:,0,:,:].values**2)+(u10D.u10[:,0,:,:].values**2))**0.5\n",
    "\n",
    "ws_ds = xr.Dataset({'ws': (('time','latitude','longitude'), ws)}, coords={'time': v10D.time,'latitude': v10D.latitude,'longitude': v10D.longitude})\n",
    "\n",
    "rh = (e**((17.625*(d2mD.d2m[:,0,:,:].values-273.15))/(243.04+(d2mD.d2m[:,0,:,:].values-273.15)))/e**((17.625*(t2mD.t2m[:,0,:,:].values-273.15))/(243.04+(t2mD.t2m[:,0,:,:].values-273.15))))\n",
    "\n",
    "rh_ds = xr.Dataset({'rh': (('time','latitude','longitude'), rh)}, coords={'time': v10D.time,'latitude': v10D.latitude,'longitude': v10D.longitude})\n",
    "\n",
    "#rh_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read 850 data\n",
    "\n",
    "tz850Data = xr.open_dataset('../../../Data/IGPERA5/DailyFiles/DailyERA5IGP_850_tqz_3hourly_NovDecJan.nc')\n",
    "\n",
    "uv850Data = xr.open_dataset('../../../Data/IGPERA5/DailyFiles/DailyERA5IGP_850_uv_3hourly_NovDecJan.nc')\n",
    "\n",
    "tz850D = tz850Data.sel(latitude=slice(32,24),longitude=slice(74,86))\n",
    "\n",
    "uv850D = uv850Data.sel(latitude=slice(32,24),longitude=slice(74,86))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate inv\n",
    "\n",
    "inv=t2mD.t2m[:,0,:,:].values-tz850D.t[:,0,:,:].values\n",
    "\n",
    "inv_ds = xr.Dataset({'inv': (('time','latitude','longitude'), inv)}, coords={'time': v10D.time,'latitude': v10D.latitude,'longitude': v10D.longitude})\n",
    "\n",
    "inv_ds.attrs\n",
    "\n",
    "inv_ds.attrs['units']='K'\n",
    "\n",
    "inv_ds.attrs['long_name']='t2m - t850'\n",
    "\n",
    "#inv_ds.inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#u shear calculation\n",
    "\n",
    "ushear=(uv850D.u[:,0,:,:].values-u10D.u10[:,0,:,:].values)/(tz850D.z[:,0,:,:].values/9.81) \n",
    "\n",
    "ushear_ds = xr.Dataset({'ushear': (('time','latitude','longitude'), ushear)}, coords={'time': v10D.time,'latitude': v10D.latitude,'longitude': v10D.longitude})\n",
    "\n",
    "ushear_ds.attrs['units']='s-1'\n",
    "\n",
    "ushear_ds.attrs['long_name']='(u10 - u850)/z850'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "w700Data = xr.open_dataset('../../../Data/IGPERA5/DailyFiles/DailyERA5IGP_700_w_3hourly_NovDecJan.nc')\n",
    "\n",
    "w700D = w700Data.sel(latitude=slice(32,24),longitude=slice(74,86))\n",
    "\n",
    "# Read Orography\n",
    "\n",
    "OroData = xr.open_dataset('../../../Data/IGPERA5/DailyFiles/ERA5IGP_Orography.nc')\n",
    "\n",
    "OroData.data_vars\n",
    "\n",
    "OroD = OroData.sel(latitude=slice(32,24),longitude=slice(74,86))\n",
    "\n",
    "oro = OroD.z\n",
    "\n",
    "oro.values = OroD.z.values/9.81\n",
    "\n",
    "oro.attrs\n",
    "\n",
    "oro.attrs['units']='meter'\n",
    "\n",
    "oro.attrs['long_name']='Orography'\n",
    "\n",
    "l = np.arange(0,1000,100)\n",
    "\n",
    "#oro[0,:,:].plot(levels=l,extend='both',cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Mask altitude >500 m NaN\n",
    "\n",
    "oro.values[oro.values>500.1]=np.NaN\n",
    "\n",
    "mask=oro.values/oro.values\n",
    "\n",
    "# chk mask\n",
    "\n",
    "t2mD.t2m.values=t2mD.t2m.values*mask\n",
    "\n",
    "#t2mData.t2m[0,0,:,:].plot(cmap='jet')\n",
    "\n",
    "#plt.figure(figsize=[20,10])\n",
    "\n",
    "#t2mData.mean(dim=['latitude','longitude']).t2m[:,0].plot()\n",
    "\n",
    "t2mTS=t2mD.mean(dim=['latitude','longitude'], skipna=True).t2m[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_ds.ws.values=ws_ds.ws.values*mask\n",
    "wsTS=ws_ds.mean(dim=['latitude','longitude'], skipna=True).ws\n",
    "#wsTS.plot()\n",
    "rh_ds.rh.values=rh_ds.rh.values*mask\n",
    "#rh_ds.rh[:].mean(dim=['latitude','longitude'], skipna=True).plot()\n",
    "rhTS=rh_ds.mean(dim=['latitude','longitude'], skipna=True).rh\n",
    "rhTS.plot()\n",
    "w700D.w.values=w700D.w.values*mask\n",
    "w700D.mean(dim=['latitude','longitude'])\n",
    "wTS=w700D.mean(dim=['latitude','longitude'], skipna=True).w[:,0]\n",
    "#wTS.plot()\n",
    "inv_ds.inv.values=inv_ds.inv.values*mask\n",
    "invTS=inv_ds.mean(dim=['latitude','longitude'], skipna=True).inv\n",
    "#invTS.plot()\n",
    "ushear_ds.ushear.values=ushear_ds.ushear.values*mask\n",
    "ushearTS=ushear_ds.mean(dim=['latitude','longitude'], skipna=True).ushear\n",
    "#ushearTS.plot()\n",
    "#Create area averaged values and get same days as fog days i.e. Dec Jan\n",
    "\n",
    "# a,b = xr.align(fg.fogdata.sum(dim='stations'),t2mTS)\n",
    "\n",
    "t2m=t2mTS[((t2mTS.time.dt.month>11) | (t2mTS.time.dt.month<2)) & (t2mTS.time.dt.year<2020)].sel(time=slice('1980-1-1','2014-12-31'))\n",
    "\n",
    "ws=wsTS[((wsTS.time.dt.month>11) | (wsTS.time.dt.month<2)) & (wsTS.time.dt.year<2020)].sel(time=slice('1980-1-1','2014-12-31'))\n",
    "\n",
    "inv=invTS[((wsTS.time.dt.month>11) | (wsTS.time.dt.month<2)) & (wsTS.time.dt.year<2020)].sel(time=slice('1980-1-1','2014-12-31'))\n",
    "\n",
    "rh=rhTS[((wsTS.time.dt.month>11) | (wsTS.time.dt.month<2)) & (wsTS.time.dt.year<2020)].sel(time=slice('1980-1-1','2014-12-31'))\n",
    "\n",
    "w=wTS[((wsTS.time.dt.month>11) | (wsTS.time.dt.month<2)) & (wsTS.time.dt.year<2020)].sel(time=slice('1980-1-1','2014-12-31'))\n",
    "\n",
    "ushear=ushearTS[((wsTS.time.dt.month>11) | (wsTS.time.dt.month<2)) & (wsTS.time.dt.year<2020)].sel(time=slice('1980-1-1','2014-12-31'))\n",
    "\n",
    "#t2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X       = pd.DataFrame([t2m.values,ws.values,rh.values,inv.values,w.values,ushear.values*100.0]).T[:]\n",
    "X.index = pd.to_datetime(t2m.time.values)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=fg.fogdata.sum(dim='stations').sel(time=slice('1980-1-1','2014-12-31'))\n",
    "y=y/25.0\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a classifier\n",
    "gbReg = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n",
    "                  .format(results['mean_test_score'][candidate],\n",
    "                          results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "#=20, max_depth= 3,learning_rate=0.04,\n",
    "param_dist = {'n_estimators':[300,500,1000,1500,2000,2500,3000],\n",
    "              'min_samples_leaf': [5,10,15,20],\n",
    "              'max_depth': [2,3,4],\n",
    "              'learning_rate': [0.1,0.2,0.3,0.05,0.03,0.02,0.01]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(gbReg, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a classifier\n",
    "gbReg = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n",
    "                  .format(results['mean_test_score'][candidate],\n",
    "                          results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "#=20, max_depth= 3,learning_rate=0.04,\n",
    "param_dist = {'n_estimators':[300,500,1000],\n",
    "              'min_samples_leaf': [5,10,15],\n",
    "              'max_depth': [2,3,4],\n",
    "              'learning_rate': [0.1,0.3,0.05,0.01]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(gbReg, param_grid=param_dist,scoring='r2',cv=5)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = SVR(C= 5, gamma='auto', kernel= 'rbf')\n",
    "\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prediction_rmm1 = regressor.predict(X_test)\n",
    "\n",
    "acc_svr       = round(regressor.score(X_test, y_test) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of base SVR model is ,\",(acc_svr/100)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svReg = SVR()\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\"\n",
    "                  .format(results['mean_test_score'][candidate],\n",
    "                          results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "#=20, max_depth= 3,learning_rate=0.04,\n",
    "param_dist = {'kernel':[ 'rbf' ],\n",
    "              'gamma': ['scale', 'auto'],\n",
    "              'C': [1,2,3,4,5,6],\n",
    "              }\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(svReg, param_grid=param_dist,scoring='r2',cv=5)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=GradientBoostingRegressor(n_estimators=300, min_samples_leaf=20, max_depth= 3,learning_rate=0.04,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prediction_rmm1 = regressor.predict(X_test)\n",
    "\n",
    "acc_svr       = round(regressor.score(X_test, y_test) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy of GB model is ,\",(acc_svr/100)**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = XGBRegressor(n_estimators=100,learning_rate=0.05,max_depth=5,objective ='reg:squarederror' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_svr       = round(model.score(X_test, y_test) * 100, 2)\n",
    "print(\"Accuracy of XGB model is ,\",(acc_svr/100)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten,MaxPooling2D,AveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
