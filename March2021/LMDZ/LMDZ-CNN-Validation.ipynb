{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv3D, Flatten,MaxPooling3D,AveragePooling3D, concatenate,Input ,SpatialDropout3D,Dropout\n",
    "import keras\n",
    "from math import e\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump, load\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Orography\n",
    "OroData = xr.open_dataset('../../../Data/eraDown/ERA5_2degree_Down/DailyMean/ERA5IGP_Orography.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Surface data\n",
    "t2mData = xr.open_dataset('../../../Data/LMDZ_Data/RegridLMDZOR-HIST-t2m_1979-2005_NDJ_1D_histday.nc')\n",
    "rhData  = xr.open_dataset('../../../Data/LMDZ_Data/RegridLMDZOR-HIST-rh2m_1979-2005_NDJ_1D_histday.nc')\n",
    "u10Data = xr.open_dataset('../../../Data/LMDZ_Data/RegridLMDZOR-HIST-u10m_1979-2005_NDJ_1D_histday.nc')\n",
    "v10Data = xr.open_dataset('../../../Data/LMDZ_Data/RegridLMDZOR-HIST-V10M_1979-2005_NDJ_1D_histday.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level Data\n",
    "tLevData = xr.open_dataset('../../../Data/LMDZ_Data/RegridLMDZOR-HIST-t850_1979-2005_NDJ_1D_histday.nc')\n",
    "zLevData = xr.open_dataset('../../../Data/LMDZ_Data/RegridLMDZOR-HIST-z850_1979-2005_NDJ_1D_histday.nc')\n",
    "wLevData = xr.open_dataset('../../../Data/LMDZ_Data/RegridLMDZOR-HIST-w700_1979-2005_NDJ_1D_histday.nc')\n",
    "uLevData = xr.open_dataset('../../../Data/LMDZ_Data/RegridLMDZOR-HIST-u850_1979-2005_NDJ_1D_histday.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-66baf6541250>:2: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = t2m1.indexes['time'].to_datetimeindex()\n",
      "<ipython-input-6-66baf6541250>:6: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = u101.indexes['time'].to_datetimeindex()\n",
      "<ipython-input-6-66baf6541250>:10: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = v101.indexes['time'].to_datetimeindex()\n",
      "<ipython-input-6-66baf6541250>:14: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = rh1.indexes['time'].to_datetimeindex()\n",
      "<ipython-input-6-66baf6541250>:18: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = tLev1.indexes['time'].to_datetimeindex()\n",
      "<ipython-input-6-66baf6541250>:22: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = uLev1.indexes['time'].to_datetimeindex()\n",
      "<ipython-input-6-66baf6541250>:26: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = w7001.indexes['time'].to_datetimeindex()\n",
      "<ipython-input-6-66baf6541250>:30: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = zLev1.indexes['time'].to_datetimeindex()\n"
     ]
    }
   ],
   "source": [
    "t2m1=t2mData.t2m.rename({'time_counter':'time'})\n",
    "datetimeindex = t2m1.indexes['time'].to_datetimeindex()\n",
    "t2m1['time'] = datetimeindex\n",
    "\n",
    "u101=u10Data.u10m.rename({'time_counter':'time'})\n",
    "datetimeindex = u101.indexes['time'].to_datetimeindex()\n",
    "u101['time'] = datetimeindex\n",
    "\n",
    "v101=v10Data.v10m.rename({'time_counter':'time'})\n",
    "datetimeindex = v101.indexes['time'].to_datetimeindex()\n",
    "v101['time'] = datetimeindex\n",
    "\n",
    "rh1=rhData.rh2m.rename({'time_counter':'time'})\n",
    "datetimeindex = rh1.indexes['time'].to_datetimeindex()\n",
    "rh1['time'] = datetimeindex\n",
    "\n",
    "tLev1=tLevData.t850.rename({'time_counter':'time'})\n",
    "datetimeindex = tLev1.indexes['time'].to_datetimeindex()\n",
    "tLev1['time'] = datetimeindex\n",
    "\n",
    "uLev1=uLevData.u850.rename({'time_counter':'time'})\n",
    "datetimeindex = uLev1.indexes['time'].to_datetimeindex()\n",
    "uLev1['time'] = datetimeindex\n",
    "\n",
    "w7001=wLevData.w700.rename({'time_counter':'time'})\n",
    "datetimeindex = w7001.indexes['time'].to_datetimeindex()\n",
    "w7001['time'] = datetimeindex\n",
    "\n",
    "zLev1=zLevData.z850.rename({'time_counter':'time'})\n",
    "datetimeindex = zLev1.indexes['time'].to_datetimeindex()\n",
    "zLev1['time'] = datetimeindex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate wind speed and relative humidity inv  ushear\n",
    "ws = ((v101.values**2)+(u101.values**2))**0.5\n",
    "ws_ds = xr.Dataset({'ws': (('time','latitude','longitude'), ws)},\n",
    "                   coords={'time': v101.time,'latitude': v101.latitude,'longitude': v101.longitude})\n",
    "\n",
    "rh_ds = xr.Dataset({'rh': (('time','latitude','longitude'), rh1/100.0)},\n",
    "                   coords={'time': v101.time,'latitude': v101.latitude,'longitude': v101.longitude})\n",
    "\n",
    "#Calculate inv\n",
    "inv=t2m1.values-tLev1.values\n",
    "inv_ds = xr.Dataset({'inv': (('time','latitude','longitude'), inv)}, coords={'time': v101.time,'latitude': v101.latitude,'longitude': v101.longitude})\n",
    "inv_ds.attrs\n",
    "inv_ds.attrs['units']='K'\n",
    "inv_ds.attrs['long_name']='t2m - t850'\n",
    "\n",
    "#u shear calculation\n",
    "ushear=(uLev1.values-u101.values)/(zLev1.values) \n",
    "ushear_ds = xr.Dataset({'ushear': (('time','latitude','longitude'), ushear)}, coords={'time': v101.time,'latitude': v101.latitude,'longitude': v101.longitude})\n",
    "ushear_ds.attrs['units']='s-1'\n",
    "ushear_ds.attrs['long_name']='(u10 - u850)/z850'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AO data\n",
    "AOData = xr.open_dataset('LMDZ-AOindex-NDJF-Daily-1980-2014.nc')\n",
    "aoTS=AOData.AO\n",
    "\n",
    "Darray=np.zeros((AOData.time.shape[0],t2m1.latitude.shape[0], t2m1.longitude.shape[0]))\n",
    "for t in range(aoTS.time.shape[0]) :\n",
    "    Darray[t,:,:]=np.full((t2m1.latitude.shape[0], t2m1.longitude.shape[0]), aoTS[t].values)\n",
    "AOData=xr.Dataset({'AO': (('time','latitude','longitude'), Darray)},\n",
    "                  coords={'time': aoTS.time,'latitude': t2m1.latitude,'longitude': t2m1.longitude}) \n",
    "# EU data\n",
    "EUData = xr.open_dataset('LMDZ-EUindex-NDJF-Daily-1980-2014.nc')\n",
    "EUData.EU\n",
    "euTS=EUData.EU\n",
    "\n",
    "Darray=np.zeros((EUData.time.shape[0],t2m1.latitude.shape[0], t2m1.longitude.shape[0]))\n",
    "for t in range(euTS.time.shape[0]) :\n",
    "    Darray[t,:,:]=np.full((t2m1.latitude.shape[0], t2m1.longitude.shape[0]), euTS[t].values)\n",
    "EUData=xr.Dataset({'EU': (('time','latitude','longitude'), Darray)},\n",
    "                  coords={'time': euTS.time,'latitude': t2m1.latitude,'longitude': t2m1.longitude})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mask\n",
    "oro = OroData.z.sel(latitude=slice(35,0),longitude=slice(50,100))\n",
    "oro.values = OroData.z.sel(latitude=slice(35,0),longitude=slice(50,100)).values/9.81\n",
    "oro.attrs\n",
    "oro.attrs['units']='meter'\n",
    "oro.attrs['long_name']='Orography'\n",
    "oro.values[oro.values>500.1]=np.NaN\n",
    "mask=oro.values/oro.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AO\n",
    "AO5D=AOData.AO.rolling(time=5).mean()\n",
    "\n",
    "AO5DAll=AO5D[((AO5D.time.dt.month>11) | (AO5D.time.dt.month<2)) & \n",
    "             (AO5D.time.dt.year<2020)].sel(time=slice('1980-1-1','2014-12-31'),latitude=slice(35,0),\n",
    "                                           longitude=slice(50,100))\n",
    "\n",
    "#EU\n",
    "EU5D=EUData.EU.rolling(time=5).mean()\n",
    "\n",
    "EU5DAll=EU5D[((EU5D.time.dt.month>11) | (EU5D.time.dt.month<2)) & \n",
    "             (EU5D.time.dt.year<2020)].sel(time=slice('1980-1-1','2014-12-31'),latitude=slice(35,0),\n",
    "                                           longitude=slice(50,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=AO5DAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "# fit scaler on training data\n",
    "norm = StandardScaler().fit(t1)\n",
    "# transform training data\n",
    "t1.values = norm.transform(t1)\n",
    "AO5DAll.values=t1.unstack()\n",
    "\n",
    "t1=EU5DAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "# fit scaler on training data\n",
    "norm = StandardScaler().fit(t1)\n",
    "# transform training data\n",
    "t1.values = norm.transform(t1)\n",
    "EU5DAll.values=t1.unstack()\n",
    "\n",
    "AO5DAll.values=AO5DAll.values*mask\n",
    "AO5DAll.values=xr.where(np.isnan(AO5DAll.values),  0.000000000001,AO5DAll.values)\n",
    "\n",
    "EU5DAll.values=EU5DAll.values*mask\n",
    "EU5DAll.values=xr.where(np.isnan(EU5DAll.values),  0.000000000001,EU5DAll.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m=t2m1.shift(time=1)\n",
    "ws=ws_ds.ws.shift(time=1)\n",
    "rh=rh_ds.rh.shift(time=1)\n",
    "inv=inv_ds.inv.shift(time=1)\n",
    "w=w7001.shift(time=1)\n",
    "ushear=ushear_ds.ushear.shift(time=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "datetimeindex = t2m.indexes['time'].to_datetimeindex()\n",
    "t2m['time'] = datetimeindex\n",
    "ws['time'] = datetimeindex\n",
    "rh['time'] = datetimeindex\n",
    "inv['time'] = datetimeindex\n",
    "w['time'] = datetimeindex\n",
    "ushear['time'] = datetimeindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2mTsAll=t2m[((t2m.time.dt.month>11) | (t2m.time.dt.month<2)) & (t2m.time.dt.year<2020)].sel(time=slice('1980-1-1','2005-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "wsTsAll=ws[((ws.time.dt.month>11) | (ws.time.dt.month<2)) & (ws.time.dt.year<2020)].sel(time=slice('1980-1-1','2005-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "rhTsAll=rh[((rh.time.dt.month>11) | (rh.time.dt.month<2)) & (rh.time.dt.year<2020)].sel(time=slice('1980-1-1','2005-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "invTsAll=inv[((inv.time.dt.month>11) | (inv.time.dt.month<2)) & (inv.time.dt.year<2020)].sel(time=slice('1980-1-1','2005-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "ushearTsAll=ushear[((ushear.time.dt.month>11) | (ushear.time.dt.month<2)) & (ushear.time.dt.year<2020)].sel(time=slice('1980-1-1','2005-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "wTsAll=w[((w.time.dt.month>11) | (w.time.dt.month<2)) & (w.time.dt.year<2020)].sel(time=slice('1980-1-1','2005-12-31'),latitude=slice(35,0),longitude=slice(50,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cccr/diptih/anaconda3/lib/python3.8/site-packages/sklearn/utils/extmath.py:847: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/cccr/diptih/anaconda3/lib/python3.8/site-packages/sklearn/utils/extmath.py:687: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs, dtype=np.float64)\n",
      "/home/cccr/diptih/anaconda3/lib/python3.8/site-packages/sklearn/utils/extmath.py:847: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/cccr/diptih/anaconda3/lib/python3.8/site-packages/sklearn/utils/extmath.py:687: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs, dtype=np.float64)\n",
      "/home/cccr/diptih/anaconda3/lib/python3.8/site-packages/sklearn/utils/extmath.py:847: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/home/cccr/diptih/anaconda3/lib/python3.8/site-packages/sklearn/utils/extmath.py:687: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs, dtype=np.float64)\n"
     ]
    }
   ],
   "source": [
    "t1=t2mTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "# fit scaler on training data\n",
    "norm = StandardScaler().fit(t1)\n",
    "# transform training data\n",
    "t1.values = norm.transform(t1)\n",
    "t2mTsAll.values=t1.unstack()\n",
    "\n",
    "t1=wsTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "# fit scaler on training data\n",
    "norm = StandardScaler().fit(t1)\n",
    "# transform training data\n",
    "t1.values = norm.transform(t1)\n",
    "wsTsAll.values=t1.unstack()\n",
    "\n",
    "t1=rhTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "# fit scaler on training data\n",
    "norm = StandardScaler().fit(t1)\n",
    "# transform training data\n",
    "t1.values = norm.transform(t1)\n",
    "rhTsAll.values=t1.unstack()\n",
    "\n",
    "t1=invTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "# fit scaler on training data\n",
    "norm = StandardScaler().fit(t1)\n",
    "# transform training data\n",
    "t1.values = norm.transform(t1)\n",
    "invTsAll.values=t1.unstack()\n",
    "\n",
    "t1=ushearTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "# fit scaler on training data\n",
    "norm = StandardScaler().fit(t1)\n",
    "# transform training data\n",
    "t1.values = norm.transform(t1)\n",
    "ushearTsAll.values=t1.unstack()\n",
    "\n",
    "\n",
    "t1=wTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "# fit scaler on training data\n",
    "norm = StandardScaler().fit(t1)\n",
    "# transform training data\n",
    "t1.values = norm.transform(t1)\n",
    "wTsAll.values=t1.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2mTsAll.values=t2mTsAll.values*mask\n",
    "wsTsAll.values=wsTsAll.values*mask\n",
    "rhTsAll.values=rhTsAll.values*mask\n",
    "invTsAll.values=invTsAll.values*mask\n",
    "ushearTsAll.values=ushearTsAll.values*mask\n",
    "wTsAll.values=wTsAll.values*mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2mTsAll.values=xr.where(np.isnan(t2mTsAll.values),  0.000000000001,t2mTsAll.values)\n",
    "wsTsAll.values=xr.where(np.isnan(wsTsAll.values),  0.000000000001,wsTsAll.values)\n",
    "rhTsAll.values=xr.where(np.isnan(rhTsAll.values),  0.000000000001,rhTsAll.values)\n",
    "invTsAll.values=xr.where(np.isnan(invTsAll.values),  0.000000000001,invTsAll.values)\n",
    "ushearTsAll.values=xr.where(np.isnan(ushearTsAll.values),  0.000000000001,ushearTsAll.values)\n",
    "wTsAll.values=xr.where(np.isnan(wTsAll.values),  0.000000000001,wTsAll.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1612, 18, 26, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2mt=t2mTsAll.values\n",
    "t2mt=t2mt[:,:,:,None]\n",
    "t2mt.shape\n",
    "\n",
    "\n",
    "wst=wsTsAll.values\n",
    "wst=wst[:,:,:,None]\n",
    "wst.shape\n",
    "\n",
    "rht=rhTsAll.values\n",
    "rht=rht[:,:,:,None]\n",
    "rht.shape\n",
    "\n",
    "\n",
    "invt=invTsAll.values\n",
    "invt=invt[:,:,:,None]\n",
    "invt.shape\n",
    "\n",
    "wt=wTsAll.values\n",
    "wt=wt[:,:,:,None]\n",
    "wt.shape\n",
    "\n",
    "usheart=ushearTsAll.values\n",
    "usheart=usheart[:,:,:,None]\n",
    "usheart.shape\n",
    "\n",
    "aot=AO5DAll.values\n",
    "aot=aot[:,:,:,None]\n",
    "aot.shape\n",
    "\n",
    "eut=EU5DAll.values\n",
    "eut=eut[:,:,:,None]\n",
    "eut.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1612, 18, 26, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=np.array([t2mt,rht,wst,invt,wt,usheart,aot,eut])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1612, 8, 18, 26, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reshape = np.einsum('lkija->klija',X)\n",
    "X_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 8, 18, 26, 16)     448       \n",
      "_________________________________________________________________\n",
      "average_pooling3d (AveragePo (None, 4, 9, 13, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 4, 9, 13, 32)      13856     \n",
      "_________________________________________________________________\n",
      "average_pooling3d_1 (Average (None, 2, 5, 7, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2, 5, 7, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 2, 5, 7, 64)       55360     \n",
      "_________________________________________________________________\n",
      "average_pooling3d_2 (Average (None, 1, 3, 4, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 3, 4, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                24608     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 94,305\n",
      "Trainable params: 94,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load saved model\n",
    "# load model\n",
    "model = load_model('../../March2021/Observation_models/modelCNN.h5')\n",
    "# summarize model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "yLR=model.predict(X_reshape)\n",
    "y_predLin_ds=xr.Dataset({'yLR': (('time'), yLR[:,0])}, coords={'time':t2mTsAll.time.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Model_plots/LMDZ-CNN-Y.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(y_predLin_ds.yLR,'../Model_plots/LMDZ-CNN-Y.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
