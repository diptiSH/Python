{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv3D, Flatten,MaxPooling3D,AveragePooling3D, concatenate,Input ,SpatialDropout3D,Dropout\n",
    "import keras\n",
    "from math import e\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump, load\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Orography\n",
    "OroData = xr.open_dataset('../../../Data/eraDown/ERA5_2degree_Down/DailyMean/ERA5IGP_Orography.nc')\n",
    "model = load_model('../../March2021/Observation_models/modelCNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCESS-CM2\n"
     ]
    }
   ],
   "source": [
    "# Read Data \n",
    "#ModelList=['ACCESS-CM2','CanESM5','IITM-ESM','INM-CM4-8','INM-CM5-0',\n",
    " #          'IPSL-CM6A-LR','MIROC6','MRI-ESM2-0','MPI-ESM1-2-LR','MPI-ESM1-2-HR','EC-Earth3']\n",
    "#varList=['hurs','ta','tas','ua','uas','vas','wap','zg']\n",
    "ModelList=['ACCESS-CM2']\n",
    "gridlist=['gn']\n",
    "\n",
    "for m,g in zip(ModelList,gridlist) :\n",
    "    print(m)\n",
    "    folderString='/home/cccr/diptih/dipti/Data/ssp126/'+m+'/processed/'\n",
    "    #print(folderString)\n",
    "    #fName=folderString+'Regrid_'+v+'_day_'+m+'_ssp126_r1i1p1f1_gn_20150101-21001231.nc'\n",
    "    t2mData=xr.open_dataset(folderString+'Regrid_tas_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(t2mData)\n",
    "    rhData=xr.open_dataset(folderString+'Regrid_hurs_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(rhData)\n",
    "    v10Data=xr.open_dataset(folderString+'Regrid_vas_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(v10Data)\n",
    "    u10Data=xr.open_dataset(folderString+'Regrid_uas_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(u10Data)\n",
    "    tLevData=xr.open_dataset(folderString+'Regrid_ta_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(tLevData)\n",
    "    zLevData=xr.open_dataset(folderString+'Regrid_zg_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(zLevData)\n",
    "    wLevData=xr.open_dataset(folderString+'Regrid_wap_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(wLevData)\n",
    "    uLevData=xr.open_dataset(folderString+'Regrid_ua_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(uLevData)\n",
    "    # Calculate wind speed and relative humidity inv  ushear\n",
    "    ws = ((v10Data.vas.values**2)+(u10Data.uas.values**2))**0.5\n",
    "    ws_ds = xr.Dataset({'ws': (('time','latitude','longitude'), ws)},\n",
    "                   coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "\n",
    "    rh_ds = xr.Dataset({'rh': (('time','latitude','longitude'), rhData.hurs/100.0)},\n",
    "                   coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "\n",
    "    #Calculate inv\n",
    "    inv=t2mData.tas.values-tLevData.ta.sel(plev=85000,method='nearest').values\n",
    "    inv_ds = xr.Dataset({'inv': (('time','latitude','longitude'), inv)}, coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "    inv_ds.attrs\n",
    "    inv_ds.attrs['units']='K'\n",
    "    inv_ds.attrs['long_name']='t2m - t850'\n",
    "\n",
    "    #u shear calculation\n",
    "    ushear=(uLevData.ua.sel(plev=85000,method='nearest').values-u10Data.uas.values)/(zLevData.zg.sel(plev=85000,method='nearest').values) \n",
    "    ushear_ds = xr.Dataset({'ushear': (('time','latitude','longitude'), ushear)}, coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "    ushear_ds.attrs['units']='s-1'\n",
    "    ushear_ds.attrs['long_name']='(u10 - u850)/z850'\n",
    "    \n",
    "\n",
    "\n",
    "    # AO data\n",
    "    AOData = xr.open_dataset(m+'-AOindex-NDJF-Daily-2015-2100.nc')\n",
    "    aoTS=AOData.AO\n",
    "        #datetimeindex = aoTS.indexes['time'].to_datetimeindex()\n",
    "    #datetimeindex\n",
    "    #aoTS['time'] = datetimeindex\n",
    "    Darray=np.zeros((AOData.time.shape[0],t2mData.latitude.shape[0], t2mData.longitude.shape[0]))\n",
    "    for t in range(aoTS.time.shape[0]) :\n",
    "        Darray[t,:,:]=np.full((t2mData.latitude.shape[0], t2mData.longitude.shape[0]), aoTS[t].values)\n",
    "    AOData=xr.Dataset({'AO': (('time','latitude','longitude'), Darray)},\n",
    "                  coords={'time': aoTS.time,'latitude': t2mData.latitude,'longitude': t2mData.longitude}) \n",
    "    # EU data\n",
    "    EUData = xr.open_dataset(m+'-EUindex-NDJF-Daily-2015-2100.nc')\n",
    "    EUData.EU\n",
    "    euTS=EUData.EU\n",
    "    #datetimeindex = euTS.indexes['time'].to_datetimeindex()\n",
    "    #datetimeindex\n",
    "    #euTS['time'] = datetimeindex\n",
    "    Darray=np.zeros((EUData.time.shape[0],t2mData.latitude.shape[0], t2mData.longitude.shape[0]))\n",
    "    for t in range(euTS.time.shape[0]) :\n",
    "        Darray[t,:,:]=np.full((t2mData.latitude.shape[0], t2mData.longitude.shape[0]), euTS[t].values)\n",
    "    EUData=xr.Dataset({'EU': (('time','latitude','longitude'), Darray)},\n",
    "                  coords={'time': euTS.time,'latitude': t2mData.latitude,'longitude': t2mData.longitude})\n",
    "    # create mask\n",
    "    oro = OroData.z.sel(latitude=slice(35,0),longitude=slice(50,100))\n",
    "    oro.values = OroData.z.sel(latitude=slice(35,0),longitude=slice(50,100)).values/9.81\n",
    "    oro.attrs\n",
    "    oro.attrs['units']='meter'\n",
    "    oro.attrs['long_name']='Orography'\n",
    "    oro.values[oro.values>500.1]=np.NaN\n",
    "    mask=oro.values/oro.values\n",
    "    #AO\n",
    "    AO5D=AOData.AO.rolling(time=5).mean()\n",
    "\n",
    "    AO5DAll=AO5D[((AO5D.time.dt.month>11) | (AO5D.time.dt.month<2)) & \n",
    "             (AO5D.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),\n",
    "                                           longitude=slice(50,100))\n",
    "\n",
    "    #EU\n",
    "    EU5D=EUData.EU.rolling(time=5).mean()\n",
    "\n",
    "    EU5DAll=EU5D[((EU5D.time.dt.month>11) | (EU5D.time.dt.month<2)) & \n",
    "             (EU5D.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),\n",
    "                                           longitude=slice(50,100))\n",
    "    \n",
    "    t1=AO5DAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/ACCESS-CM2/AO5DnormAccessCm2.joblib') \n",
    "    norm = StandardScaler().fit(t1)\n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    AO5DAll.values=t1.unstack()\n",
    "\n",
    "    t1=EU5DAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/ACCESS-CM2/EU5DnormAccessCm2.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    EU5DAll.values=t1.unstack()\n",
    "\n",
    "    AO5DAll.values=AO5DAll.values*mask\n",
    "    AO5DAll.values=xr.where(np.isnan(AO5DAll.values),  0.000000000001,AO5DAll.values)\n",
    "\n",
    "    EU5DAll.values=EU5DAll.values*mask\n",
    "    EU5DAll.values=xr.where(np.isnan(EU5DAll.values),  0.000000000001,EU5DAll.values)\n",
    "    \n",
    "    t2m=t2mData.tas.shift(time=1)\n",
    "    ws=ws_ds.ws.shift(time=1)\n",
    "    rh=rh_ds.rh.shift(time=1)\n",
    "    inv=inv_ds.inv.shift(time=1)\n",
    "    w=wLevData.wap.sel(plev=70000,method='nearest').shift(time=1)\n",
    "    ushear=ushear_ds.ushear.shift(time=1)\n",
    "    \n",
    "    t2mTsAll=t2m[((t2m.time.dt.month>11) | (t2m.time.dt.month<2)) & (t2m.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    wsTsAll=ws[((ws.time.dt.month>11) | (ws.time.dt.month<2)) & (ws.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    rhTsAll=rh[((rh.time.dt.month>11) | (rh.time.dt.month<2)) & (rh.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    invTsAll=inv[((inv.time.dt.month>11) | (inv.time.dt.month<2)) & (inv.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    ushearTsAll=ushear[((ushear.time.dt.month>11) | (ushear.time.dt.month<2)) & (ushear.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    wTsAll=w[((w.time.dt.month>11) | (w.time.dt.month<2)) & (w.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    \n",
    "    \n",
    "    t1=t2mTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/ACCESS-CM2/t2mnormAccessCm2.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    t2mTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=wsTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/ACCESS-CM2/wsnormAccessCm2.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    wsTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=rhTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/ACCESS-CM2/rhnormAccessCm2.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    rhTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=invTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/ACCESS-CM2/invnormAccessCm2.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    invTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=ushearTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/ACCESS-CM2/ushearnormAccessCm2.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    ushearTsAll.values=t1.unstack()\n",
    "\n",
    "\n",
    "    t1=wTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/ACCESS-CM2/wnormAccessCm2.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    wTsAll.values=t1.unstack()\n",
    "    \n",
    "    t2mTsAll.values=t2mTsAll.values*mask\n",
    "    wsTsAll.values=wsTsAll.values*mask\n",
    "    rhTsAll.values=rhTsAll.values*mask\n",
    "    invTsAll.values=invTsAll.values*mask\n",
    "    ushearTsAll.values=ushearTsAll.values*mask\n",
    "    wTsAll.values=wTsAll.values*mask\n",
    "    \n",
    "    t2mTsAll.values=xr.where(np.isnan(t2mTsAll.values),  0.000000000001,t2mTsAll.values)\n",
    "    wsTsAll.values=xr.where(np.isnan(wsTsAll.values),  0.000000000001,wsTsAll.values)\n",
    "    rhTsAll.values=xr.where(np.isnan(rhTsAll.values),  0.000000000001,rhTsAll.values)\n",
    "    invTsAll.values=xr.where(np.isnan(invTsAll.values),  0.000000000001,invTsAll.values)\n",
    "    ushearTsAll.values=xr.where(np.isnan(ushearTsAll.values),  0.000000000001,ushearTsAll.values)\n",
    "    wTsAll.values=xr.where(np.isnan(wTsAll.values),  0.000000000001,wTsAll.values)\n",
    "    \n",
    "    t2mt=t2mTsAll.values\n",
    "    t2mt=t2mt[:,:,:,None]\n",
    "    t2mt.shape\n",
    "\n",
    "\n",
    "    wst=wsTsAll.values\n",
    "    wst=wst[:,:,:,None]\n",
    "    wst.shape\n",
    "\n",
    "    rht=rhTsAll.values\n",
    "    rht=rht[:,:,:,None]\n",
    "    rht.shape\n",
    "\n",
    "\n",
    "    invt=invTsAll.values\n",
    "    invt=invt[:,:,:,None]\n",
    "    invt.shape\n",
    "\n",
    "    wt=wTsAll.values\n",
    "    wt=wt[:,:,:,None]\n",
    "    wt.shape\n",
    "\n",
    "    usheart=ushearTsAll.values\n",
    "    usheart=usheart[:,:,:,None]\n",
    "    usheart.shape\n",
    "\n",
    "    aot=AO5DAll.values\n",
    "    aot=aot[:,:,:,None]\n",
    "    aot.shape\n",
    "\n",
    "    eut=EU5DAll.values\n",
    "    eut=eut[:,:,:,None]\n",
    "    eut.shape\n",
    "    \n",
    "    X=np.array([t2mt,rht,wst,invt,wt,usheart,aot,eut])\n",
    "    X.shape\n",
    "    \n",
    "    X_reshape = np.einsum('lkija->klija',X)\n",
    "    X_reshape.shape\n",
    "    \n",
    "    yLR=model.predict(X_reshape)\n",
    "    y_predLin_ds=xr.Dataset({'yLR': (('time'), yLR[:,0])}, coords={'time':t2mTsAll.time.values})\n",
    "    \n",
    "    dump(y_predLin_ds.yLR,'Modelplots_future/'+m+'_ssp126.joblib')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IITM-ESM\n"
     ]
    }
   ],
   "source": [
    "# Read Data \n",
    "#ModelList=['ACCESS-CM2','CanESM5','IITM-ESM','INM-CM4-8','INM-CM5-0',\n",
    " #          'IPSL-CM6A-LR','MIROC6','MRI-ESM2-0','MPI-ESM1-2-LR','MPI-ESM1-2-HR','EC-Earth3']\n",
    "#varList=['hurs','ta','tas','ua','uas','vas','wap','zg']\n",
    "ModelList=['IITM-ESM']\n",
    "gridlist=['gn']\n",
    "normList=['IitmEsm']\n",
    "\n",
    "for m,g,n in zip(ModelList,gridlist,normList) :\n",
    "    print(m)\n",
    "    folderString='/home/cccr/diptih/dipti/Data/ssp126/'+m+'/processed/'\n",
    "    #print(folderString)\n",
    "    #fName=folderString+'Regrid_'+v+'_day_'+m+'_ssp126_r1i1p1f1_gn_20150101-21001231.nc'\n",
    "    t2mData=xr.open_dataset(folderString+'Regrid_tas_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(t2mData)\n",
    "    rhData=xr.open_dataset(folderString+'Regrid_hurs_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(rhData)\n",
    "    v10Data=xr.open_dataset(folderString+'Regrid_vas_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(v10Data)\n",
    "    u10Data=xr.open_dataset(folderString+'Regrid_uas_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(u10Data)\n",
    "    tLevData=xr.open_dataset(folderString+'Regrid_ta_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(tLevData)\n",
    "    zLevData=xr.open_dataset(folderString+'Regrid_zg_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(zLevData)\n",
    "    wLevData=xr.open_dataset(folderString+'Regrid_wap_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(wLevData)\n",
    "    uLevData=xr.open_dataset(folderString+'Regrid_ua_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(uLevData)\n",
    "    # Calculate wind speed and relative humidity inv  ushear\n",
    "    ws = ((v10Data.vas.values**2)+(u10Data.uas.values**2))**0.5\n",
    "    ws_ds = xr.Dataset({'ws': (('time','latitude','longitude'), ws)},\n",
    "                   coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "\n",
    "    rh_ds = xr.Dataset({'rh': (('time','latitude','longitude'), rhData.hurs/100.0)},\n",
    "                   coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "\n",
    "    #Calculate inv\n",
    "    inv=t2mData.tas.values-tLevData.ta.sel(plev=85000,method='nearest').values\n",
    "    inv_ds = xr.Dataset({'inv': (('time','latitude','longitude'), inv)}, coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "    inv_ds.attrs\n",
    "    inv_ds.attrs['units']='K'\n",
    "    inv_ds.attrs['long_name']='t2m - t850'\n",
    "\n",
    "    #u shear calculation\n",
    "    ushear=(uLevData.ua.sel(plev=85000,method='nearest').values-u10Data.uas.values)/(zLevData.zg.sel(plev=85000,method='nearest').values) \n",
    "    ushear_ds = xr.Dataset({'ushear': (('time','latitude','longitude'), ushear)}, coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "    ushear_ds.attrs['units']='s-1'\n",
    "    ushear_ds.attrs['long_name']='(u10 - u850)/z850'\n",
    "    \n",
    "\n",
    "\n",
    "    # AO data\n",
    "    AOData = xr.open_dataset(m+'-AOindex-NDJF-Daily-2015-2100.nc')\n",
    "    aoTS=AOData.AO\n",
    "        #datetimeindex = aoTS.indexes['time'].to_datetimeindex()\n",
    "    #datetimeindex\n",
    "    #aoTS['time'] = datetimeindex\n",
    "    Darray=np.zeros((AOData.time.shape[0],t2mData.latitude.shape[0], t2mData.longitude.shape[0]))\n",
    "    for t in range(aoTS.time.shape[0]) :\n",
    "        Darray[t,:,:]=np.full((t2mData.latitude.shape[0], t2mData.longitude.shape[0]), aoTS[t].values)\n",
    "    AOData=xr.Dataset({'AO': (('time','latitude','longitude'), Darray)},\n",
    "                  coords={'time': aoTS.time,'latitude': t2mData.latitude,'longitude': t2mData.longitude}) \n",
    "    # EU data\n",
    "    EUData = xr.open_dataset(m+'-EUindex-NDJF-Daily-2015-2100.nc')\n",
    "    EUData.EU\n",
    "    euTS=EUData.EU\n",
    "    #datetimeindex = euTS.indexes['time'].to_datetimeindex()\n",
    "    #datetimeindex\n",
    "    #euTS['time'] = datetimeindex\n",
    "    Darray=np.zeros((EUData.time.shape[0],t2mData.latitude.shape[0], t2mData.longitude.shape[0]))\n",
    "    for t in range(euTS.time.shape[0]) :\n",
    "        Darray[t,:,:]=np.full((t2mData.latitude.shape[0], t2mData.longitude.shape[0]), euTS[t].values)\n",
    "    EUData=xr.Dataset({'EU': (('time','latitude','longitude'), Darray)},\n",
    "                  coords={'time': euTS.time,'latitude': t2mData.latitude,'longitude': t2mData.longitude})\n",
    "    # create mask\n",
    "    oro = OroData.z.sel(latitude=slice(35,0),longitude=slice(50,100))\n",
    "    oro.values = OroData.z.sel(latitude=slice(35,0),longitude=slice(50,100)).values/9.81\n",
    "    oro.attrs\n",
    "    oro.attrs['units']='meter'\n",
    "    oro.attrs['long_name']='Orography'\n",
    "    oro.values[oro.values>500.1]=np.NaN\n",
    "    mask=oro.values/oro.values\n",
    "    #AO\n",
    "    AO5D=AOData.AO.rolling(time=5).mean()\n",
    "\n",
    "    AO5DAll=AO5D[((AO5D.time.dt.month>11) | (AO5D.time.dt.month<2)) & \n",
    "             (AO5D.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),\n",
    "                                           longitude=slice(50,100))\n",
    "\n",
    "    #EU\n",
    "    EU5D=EUData.EU.rolling(time=5).mean()\n",
    "\n",
    "    EU5DAll=EU5D[((EU5D.time.dt.month>11) | (EU5D.time.dt.month<2)) & \n",
    "             (EU5D.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),\n",
    "                                           longitude=slice(50,100))\n",
    "    \n",
    "    t1=AO5DAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/AO5Dnorm'+n+'.joblib') \n",
    "    norm = StandardScaler().fit(t1)\n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    AO5DAll.values=t1.unstack()\n",
    "\n",
    "    t1=EU5DAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/EU5Dnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    EU5DAll.values=t1.unstack()\n",
    "\n",
    "    AO5DAll.values=AO5DAll.values*mask\n",
    "    AO5DAll.values=xr.where(np.isnan(AO5DAll.values),  0.000000000001,AO5DAll.values)\n",
    "\n",
    "    EU5DAll.values=EU5DAll.values*mask\n",
    "    EU5DAll.values=xr.where(np.isnan(EU5DAll.values),  0.000000000001,EU5DAll.values)\n",
    "    \n",
    "    t2m=t2mData.tas.shift(time=1)\n",
    "    ws=ws_ds.ws.shift(time=1)\n",
    "    rh=rh_ds.rh.shift(time=1)\n",
    "    inv=inv_ds.inv.shift(time=1)\n",
    "    w=wLevData.wap.sel(plev=70000,method='nearest').shift(time=1)\n",
    "    ushear=ushear_ds.ushear.shift(time=1)\n",
    "    \n",
    "    t2mTsAll=t2m[((t2m.time.dt.month>11) | (t2m.time.dt.month<2)) & (t2m.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    wsTsAll=ws[((ws.time.dt.month>11) | (ws.time.dt.month<2)) & (ws.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    rhTsAll=rh[((rh.time.dt.month>11) | (rh.time.dt.month<2)) & (rh.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    invTsAll=inv[((inv.time.dt.month>11) | (inv.time.dt.month<2)) & (inv.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    ushearTsAll=ushear[((ushear.time.dt.month>11) | (ushear.time.dt.month<2)) & (ushear.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    wTsAll=w[((w.time.dt.month>11) | (w.time.dt.month<2)) & (w.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    \n",
    "    \n",
    "    t1=t2mTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/t2mnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    t2mTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=wsTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/wsnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    wsTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=rhTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/rhnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    rhTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=invTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/invnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    invTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=ushearTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/ushearnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    ushearTsAll.values=t1.unstack()\n",
    "\n",
    "\n",
    "    t1=wTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/wnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    wTsAll.values=t1.unstack()\n",
    "    \n",
    "    t2mTsAll.values=t2mTsAll.values*mask\n",
    "    wsTsAll.values=wsTsAll.values*mask\n",
    "    rhTsAll.values=rhTsAll.values*mask\n",
    "    invTsAll.values=invTsAll.values*mask\n",
    "    ushearTsAll.values=ushearTsAll.values*mask\n",
    "    wTsAll.values=wTsAll.values*mask\n",
    "    \n",
    "    t2mTsAll.values=xr.where(np.isnan(t2mTsAll.values),  0.000000000001,t2mTsAll.values)\n",
    "    wsTsAll.values=xr.where(np.isnan(wsTsAll.values),  0.000000000001,wsTsAll.values)\n",
    "    rhTsAll.values=xr.where(np.isnan(rhTsAll.values),  0.000000000001,rhTsAll.values)\n",
    "    invTsAll.values=xr.where(np.isnan(invTsAll.values),  0.000000000001,invTsAll.values)\n",
    "    ushearTsAll.values=xr.where(np.isnan(ushearTsAll.values),  0.000000000001,ushearTsAll.values)\n",
    "    wTsAll.values=xr.where(np.isnan(wTsAll.values),  0.000000000001,wTsAll.values)\n",
    "    \n",
    "    t2mt=t2mTsAll.values\n",
    "    t2mt=t2mt[:,:,:,None]\n",
    "    t2mt.shape\n",
    "\n",
    "\n",
    "    wst=wsTsAll.values\n",
    "    wst=wst[:,:,:,None]\n",
    "    wst.shape\n",
    "\n",
    "    rht=rhTsAll.values\n",
    "    rht=rht[:,:,:,None]\n",
    "    rht.shape\n",
    "\n",
    "\n",
    "    invt=invTsAll.values\n",
    "    invt=invt[:,:,:,None]\n",
    "    invt.shape\n",
    "\n",
    "    wt=wTsAll.values\n",
    "    wt=wt[:,:,:,None]\n",
    "    wt.shape\n",
    "\n",
    "    usheart=ushearTsAll.values\n",
    "    usheart=usheart[:,:,:,None]\n",
    "    usheart.shape\n",
    "\n",
    "    aot=AO5DAll.values\n",
    "    aot=aot[:,:,:,None]\n",
    "    aot.shape\n",
    "\n",
    "    eut=EU5DAll.values\n",
    "    eut=eut[:,:,:,None]\n",
    "    eut.shape\n",
    "    \n",
    "    X=np.array([t2mt,rht,wst,invt,wt,usheart,aot,eut])\n",
    "    X.shape\n",
    "    \n",
    "    X_reshape = np.einsum('lkija->klija',X)\n",
    "    X_reshape.shape\n",
    "    \n",
    "    yLR=model.predict(X_reshape)\n",
    "    y_predLin_ds=xr.Dataset({'yLR': (('time'), yLR[:,0])}, coords={'time':t2mTsAll.time.values})\n",
    "    \n",
    "    dump(y_predLin_ds.yLR,'Modelplots_future/'+m+'_ssp126.joblib')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EC-Earth3\n"
     ]
    }
   ],
   "source": [
    "# Read Data \n",
    "#ModelList=['ACCESS-CM2','CanESM5','IITM-ESM','INM-CM4-8','INM-CM5-0',\n",
    " #          'IPSL-CM6A-LR','MIROC6','MRI-ESM2-0','MPI-ESM1-2-LR','MPI-ESM1-2-HR','EC-Earth3']\n",
    "#varList=['hurs','ta','tas','ua','uas','vas','wap','zg']\n",
    "ModelList=['EC-Earth3']\n",
    "gridlist=['gr']\n",
    "normList=['EcEarth3']\n",
    "\n",
    "for m,g,n in zip(ModelList,gridlist,normList) :\n",
    "    print(m)\n",
    "    folderString='/home/cccr/diptih/dipti/Data/ssp126/'+m+'/processed/'\n",
    "    #print(folderString)\n",
    "    #fName=folderString+'Regrid_'+v+'_day_'+m+'_ssp126_r1i1p1f1_gn_20150101-21001231.nc'\n",
    "    t2mData=xr.open_dataset(folderString+'Regrid_tas_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(t2mData)\n",
    "    rhData=xr.open_dataset(folderString+'Regrid_hurs_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(rhData)\n",
    "    v10Data=xr.open_dataset(folderString+'Regrid_vas_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(v10Data)\n",
    "    u10Data=xr.open_dataset(folderString+'Regrid_uas_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(u10Data)\n",
    "    tLevData=xr.open_dataset(folderString+'Regrid_ta_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(tLevData)\n",
    "    zLevData=xr.open_dataset(folderString+'Regrid_zg_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(zLevData)\n",
    "    wLevData=xr.open_dataset(folderString+'Regrid_wap_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(wLevData)\n",
    "    uLevData=xr.open_dataset(folderString+'Regrid_ua_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(uLevData)\n",
    "    # Calculate wind speed and relative humidity inv  ushear\n",
    "    ws = ((v10Data.vas.values**2)+(u10Data.uas.values**2))**0.5\n",
    "    ws_ds = xr.Dataset({'ws': (('time','latitude','longitude'), ws)},\n",
    "                   coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "\n",
    "    rh_ds = xr.Dataset({'rh': (('time','latitude','longitude'), rhData.hurs/100.0)},\n",
    "                   coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "\n",
    "    #Calculate inv\n",
    "    inv=t2mData.tas.values-tLevData.ta.sel(plev=85000,method='nearest').values\n",
    "    inv_ds = xr.Dataset({'inv': (('time','latitude','longitude'), inv)}, coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "    inv_ds.attrs\n",
    "    inv_ds.attrs['units']='K'\n",
    "    inv_ds.attrs['long_name']='t2m - t850'\n",
    "\n",
    "    #u shear calculation\n",
    "    ushear=(uLevData.ua.sel(plev=85000,method='nearest').values-u10Data.uas.values)/(zLevData.zg.sel(plev=85000,method='nearest').values) \n",
    "    ushear_ds = xr.Dataset({'ushear': (('time','latitude','longitude'), ushear)}, coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "    ushear_ds.attrs['units']='s-1'\n",
    "    ushear_ds.attrs['long_name']='(u10 - u850)/z850'\n",
    "    \n",
    "\n",
    "\n",
    "    # AO data\n",
    "    AOData = xr.open_dataset(m+'-AOindex-NDJF-Daily-2015-2100.nc')\n",
    "    aoTS=AOData.AO\n",
    "        #datetimeindex = aoTS.indexes['time'].to_datetimeindex()\n",
    "    #datetimeindex\n",
    "    #aoTS['time'] = datetimeindex\n",
    "    Darray=np.zeros((AOData.time.shape[0],t2mData.latitude.shape[0], t2mData.longitude.shape[0]))\n",
    "    for t in range(aoTS.time.shape[0]) :\n",
    "        Darray[t,:,:]=np.full((t2mData.latitude.shape[0], t2mData.longitude.shape[0]), aoTS[t].values)\n",
    "    AOData=xr.Dataset({'AO': (('time','latitude','longitude'), Darray)},\n",
    "                  coords={'time': aoTS.time,'latitude': t2mData.latitude,'longitude': t2mData.longitude}) \n",
    "    # EU data\n",
    "    EUData = xr.open_dataset(m+'-EUindex-NDJF-Daily-2015-2100.nc')\n",
    "    EUData.EU\n",
    "    euTS=EUData.EU\n",
    "    #datetimeindex = euTS.indexes['time'].to_datetimeindex()\n",
    "    #datetimeindex\n",
    "    #euTS['time'] = datetimeindex\n",
    "    Darray=np.zeros((EUData.time.shape[0],t2mData.latitude.shape[0], t2mData.longitude.shape[0]))\n",
    "    for t in range(euTS.time.shape[0]) :\n",
    "        Darray[t,:,:]=np.full((t2mData.latitude.shape[0], t2mData.longitude.shape[0]), euTS[t].values)\n",
    "    EUData=xr.Dataset({'EU': (('time','latitude','longitude'), Darray)},\n",
    "                  coords={'time': euTS.time,'latitude': t2mData.latitude,'longitude': t2mData.longitude})\n",
    "    # create mask\n",
    "    oro = OroData.z.sel(latitude=slice(35,0),longitude=slice(50,100))\n",
    "    oro.values = OroData.z.sel(latitude=slice(35,0),longitude=slice(50,100)).values/9.81\n",
    "    oro.attrs\n",
    "    oro.attrs['units']='meter'\n",
    "    oro.attrs['long_name']='Orography'\n",
    "    oro.values[oro.values>500.1]=np.NaN\n",
    "    mask=oro.values/oro.values\n",
    "    #AO\n",
    "    AO5D=AOData.AO.rolling(time=5).mean()\n",
    "\n",
    "    AO5DAll=AO5D[((AO5D.time.dt.month>11) | (AO5D.time.dt.month<2)) & \n",
    "             (AO5D.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),\n",
    "                                           longitude=slice(50,100))\n",
    "\n",
    "    #EU\n",
    "    EU5D=EUData.EU.rolling(time=5).mean()\n",
    "\n",
    "    EU5DAll=EU5D[((EU5D.time.dt.month>11) | (EU5D.time.dt.month<2)) & \n",
    "             (EU5D.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),\n",
    "                                           longitude=slice(50,100))\n",
    "    \n",
    "    t1=AO5DAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/AO5Dnorm'+n+'.joblib') \n",
    "    norm = StandardScaler().fit(t1)\n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    AO5DAll.values=t1.unstack()\n",
    "\n",
    "    t1=EU5DAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/EU5Dnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    EU5DAll.values=t1.unstack()\n",
    "\n",
    "    AO5DAll.values=AO5DAll.values*mask\n",
    "    AO5DAll.values=xr.where(np.isnan(AO5DAll.values),  0.000000000001,AO5DAll.values)\n",
    "\n",
    "    EU5DAll.values=EU5DAll.values*mask\n",
    "    EU5DAll.values=xr.where(np.isnan(EU5DAll.values),  0.000000000001,EU5DAll.values)\n",
    "    \n",
    "    t2m=t2mData.tas.shift(time=1)\n",
    "    ws=ws_ds.ws.shift(time=1)\n",
    "    rh=rh_ds.rh.shift(time=1)\n",
    "    inv=inv_ds.inv.shift(time=1)\n",
    "    w=wLevData.wap.sel(plev=70000,method='nearest').shift(time=1)\n",
    "    ushear=ushear_ds.ushear.shift(time=1)\n",
    "    \n",
    "    t2mTsAll=t2m[((t2m.time.dt.month>11) | (t2m.time.dt.month<2)) & (t2m.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    wsTsAll=ws[((ws.time.dt.month>11) | (ws.time.dt.month<2)) & (ws.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    rhTsAll=rh[((rh.time.dt.month>11) | (rh.time.dt.month<2)) & (rh.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    invTsAll=inv[((inv.time.dt.month>11) | (inv.time.dt.month<2)) & (inv.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    ushearTsAll=ushear[((ushear.time.dt.month>11) | (ushear.time.dt.month<2)) & (ushear.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    wTsAll=w[((w.time.dt.month>11) | (w.time.dt.month<2)) & (w.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    \n",
    "    \n",
    "    t1=t2mTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/t2mnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    t2mTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=wsTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/wsnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    wsTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=rhTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/rhnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    rhTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=invTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/invnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    invTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=ushearTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/ushearnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    ushearTsAll.values=t1.unstack()\n",
    "\n",
    "\n",
    "    t1=wTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/wnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    wTsAll.values=t1.unstack()\n",
    "    \n",
    "    t2mTsAll.values=t2mTsAll.values*mask\n",
    "    wsTsAll.values=wsTsAll.values*mask\n",
    "    rhTsAll.values=rhTsAll.values*mask\n",
    "    invTsAll.values=invTsAll.values*mask\n",
    "    ushearTsAll.values=ushearTsAll.values*mask\n",
    "    wTsAll.values=wTsAll.values*mask\n",
    "    \n",
    "    t2mTsAll.values=xr.where(np.isnan(t2mTsAll.values),  0.000000000001,t2mTsAll.values)\n",
    "    wsTsAll.values=xr.where(np.isnan(wsTsAll.values),  0.000000000001,wsTsAll.values)\n",
    "    rhTsAll.values=xr.where(np.isnan(rhTsAll.values),  0.000000000001,rhTsAll.values)\n",
    "    invTsAll.values=xr.where(np.isnan(invTsAll.values),  0.000000000001,invTsAll.values)\n",
    "    ushearTsAll.values=xr.where(np.isnan(ushearTsAll.values),  0.000000000001,ushearTsAll.values)\n",
    "    wTsAll.values=xr.where(np.isnan(wTsAll.values),  0.000000000001,wTsAll.values)\n",
    "    \n",
    "    t2mt=t2mTsAll.values\n",
    "    t2mt=t2mt[:,:,:,None]\n",
    "    t2mt.shape\n",
    "\n",
    "\n",
    "    wst=wsTsAll.values\n",
    "    wst=wst[:,:,:,None]\n",
    "    wst.shape\n",
    "\n",
    "    rht=rhTsAll.values\n",
    "    rht=rht[:,:,:,None]\n",
    "    rht.shape\n",
    "\n",
    "\n",
    "    invt=invTsAll.values\n",
    "    invt=invt[:,:,:,None]\n",
    "    invt.shape\n",
    "\n",
    "    wt=wTsAll.values\n",
    "    wt=wt[:,:,:,None]\n",
    "    wt.shape\n",
    "\n",
    "    usheart=ushearTsAll.values\n",
    "    usheart=usheart[:,:,:,None]\n",
    "    usheart.shape\n",
    "\n",
    "    aot=AO5DAll.values\n",
    "    aot=aot[:,:,:,None]\n",
    "    aot.shape\n",
    "\n",
    "    eut=EU5DAll.values\n",
    "    eut=eut[:,:,:,None]\n",
    "    eut.shape\n",
    "    \n",
    "    X=np.array([t2mt,rht,wst,invt,wt,usheart,aot,eut])\n",
    "    X.shape\n",
    "    \n",
    "    X_reshape = np.einsum('lkija->klija',X)\n",
    "    X_reshape.shape\n",
    "    \n",
    "    yLR=model.predict(X_reshape)\n",
    "    y_predLin_ds=xr.Dataset({'yLR': (('time'), yLR[:,0])}, coords={'time':t2mTsAll.time.values})\n",
    "    \n",
    "    dump(y_predLin_ds.yLR,'Modelplots_future/'+m+'_ssp126.joblib')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPSL-CM6A-LR\n"
     ]
    }
   ],
   "source": [
    "# Read Data \n",
    "#ModelList=['ACCESS-CM2','CanESM5','IITM-ESM','INM-CM4-8','INM-CM5-0',\n",
    " #          'IPSL-CM6A-LR','MIROC6','MRI-ESM2-0','MPI-ESM1-2-LR','MPI-ESM1-2-HR','EC-Earth3']\n",
    "#varList=['hurs','ta','tas','ua','uas','vas','wap','zg']\n",
    "ModelList=['IPSL-CM6A-LR']\n",
    "gridlist=['gr']\n",
    "normList=['IpslCm6aLr']\n",
    "\n",
    "for m,g,n in zip(ModelList,gridlist,normList) :\n",
    "    print(m)\n",
    "    folderString='/home/cccr/diptih/dipti/Data/ssp126/'+m+'/processed/'\n",
    "    #print(folderString)\n",
    "    #fName=folderString+'Regrid_'+v+'_day_'+m+'_ssp126_r1i1p1f1_gn_20150101-21001231.nc'\n",
    "    t2mData=xr.open_dataset(folderString+'Regrid_tas_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(t2mData)\n",
    "    rhData=xr.open_dataset(folderString+'Regrid_hurs_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(rhData)\n",
    "    v10Data=xr.open_dataset(folderString+'Regrid_vas_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(v10Data)\n",
    "    u10Data=xr.open_dataset(folderString+'Regrid_uas_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(u10Data)\n",
    "    tLevData=xr.open_dataset(folderString+'Regrid_ta_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(tLevData)\n",
    "    zLevData=xr.open_dataset(folderString+'Regrid_zg_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(zLevData)\n",
    "    wLevData=xr.open_dataset(folderString+'Regrid_wap_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(wLevData)\n",
    "    uLevData=xr.open_dataset(folderString+'Regrid_ua_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(uLevData)\n",
    "    # Calculate wind speed and relative humidity inv  ushear\n",
    "    ws = ((v10Data.vas.values**2)+(u10Data.uas.values**2))**0.5\n",
    "    ws_ds = xr.Dataset({'ws': (('time','latitude','longitude'), ws)},\n",
    "                   coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "\n",
    "    rh_ds = xr.Dataset({'rh': (('time','latitude','longitude'), rhData.hurs/100.0)},\n",
    "                   coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "\n",
    "    #Calculate inv\n",
    "    inv=t2mData.tas.values-tLevData.ta.sel(plev=85000,method='nearest').values\n",
    "    inv_ds = xr.Dataset({'inv': (('time','latitude','longitude'), inv)}, coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "    inv_ds.attrs\n",
    "    inv_ds.attrs['units']='K'\n",
    "    inv_ds.attrs['long_name']='t2m - t850'\n",
    "\n",
    "    #u shear calculation\n",
    "    ushear=(uLevData.ua.sel(plev=85000,method='nearest').values-u10Data.uas.values)/(zLevData.zg.sel(plev=85000,method='nearest').values) \n",
    "    ushear_ds = xr.Dataset({'ushear': (('time','latitude','longitude'), ushear)}, coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "    ushear_ds.attrs['units']='s-1'\n",
    "    ushear_ds.attrs['long_name']='(u10 - u850)/z850'\n",
    "    \n",
    "\n",
    "\n",
    "    # AO data\n",
    "    AOData = xr.open_dataset(m+'-AOindex-NDJF-Daily-2015-2100.nc')\n",
    "    aoTS=AOData.AO\n",
    "        #datetimeindex = aoTS.indexes['time'].to_datetimeindex()\n",
    "    #datetimeindex\n",
    "    #aoTS['time'] = datetimeindex\n",
    "    Darray=np.zeros((AOData.time.shape[0],t2mData.latitude.shape[0], t2mData.longitude.shape[0]))\n",
    "    for t in range(aoTS.time.shape[0]) :\n",
    "        Darray[t,:,:]=np.full((t2mData.latitude.shape[0], t2mData.longitude.shape[0]), aoTS[t].values)\n",
    "    AOData=xr.Dataset({'AO': (('time','latitude','longitude'), Darray)},\n",
    "                  coords={'time': aoTS.time,'latitude': t2mData.latitude,'longitude': t2mData.longitude}) \n",
    "    # EU data\n",
    "    EUData = xr.open_dataset(m+'-EUindex-NDJF-Daily-2015-2100.nc')\n",
    "    EUData.EU\n",
    "    euTS=EUData.EU\n",
    "    #datetimeindex = euTS.indexes['time'].to_datetimeindex()\n",
    "    #datetimeindex\n",
    "    #euTS['time'] = datetimeindex\n",
    "    Darray=np.zeros((EUData.time.shape[0],t2mData.latitude.shape[0], t2mData.longitude.shape[0]))\n",
    "    for t in range(euTS.time.shape[0]) :\n",
    "        Darray[t,:,:]=np.full((t2mData.latitude.shape[0], t2mData.longitude.shape[0]), euTS[t].values)\n",
    "    EUData=xr.Dataset({'EU': (('time','latitude','longitude'), Darray)},\n",
    "                  coords={'time': euTS.time,'latitude': t2mData.latitude,'longitude': t2mData.longitude})\n",
    "    # create mask\n",
    "    oro = OroData.z.sel(latitude=slice(35,0),longitude=slice(50,100))\n",
    "    oro.values = OroData.z.sel(latitude=slice(35,0),longitude=slice(50,100)).values/9.81\n",
    "    oro.attrs\n",
    "    oro.attrs['units']='meter'\n",
    "    oro.attrs['long_name']='Orography'\n",
    "    oro.values[oro.values>500.1]=np.NaN\n",
    "    mask=oro.values/oro.values\n",
    "    #AO\n",
    "    AO5D=AOData.AO.rolling(time=5).mean()\n",
    "\n",
    "    AO5DAll=AO5D[((AO5D.time.dt.month>11) | (AO5D.time.dt.month<2)) & \n",
    "             (AO5D.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),\n",
    "                                           longitude=slice(50,100))\n",
    "\n",
    "    #EU\n",
    "    EU5D=EUData.EU.rolling(time=5).mean()\n",
    "\n",
    "    EU5DAll=EU5D[((EU5D.time.dt.month>11) | (EU5D.time.dt.month<2)) & \n",
    "             (EU5D.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),\n",
    "                                           longitude=slice(50,100))\n",
    "    \n",
    "    t1=AO5DAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/AO5Dnorm'+n+'.joblib') \n",
    "    norm = StandardScaler().fit(t1)\n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    AO5DAll.values=t1.unstack()\n",
    "\n",
    "    t1=EU5DAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/EU5Dnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    EU5DAll.values=t1.unstack()\n",
    "\n",
    "    AO5DAll.values=AO5DAll.values*mask\n",
    "    AO5DAll.values=xr.where(np.isnan(AO5DAll.values),  0.000000000001,AO5DAll.values)\n",
    "\n",
    "    EU5DAll.values=EU5DAll.values*mask\n",
    "    EU5DAll.values=xr.where(np.isnan(EU5DAll.values),  0.000000000001,EU5DAll.values)\n",
    "    \n",
    "    t2m=t2mData.tas.shift(time=1)\n",
    "    ws=ws_ds.ws.shift(time=1)\n",
    "    rh=rh_ds.rh.shift(time=1)\n",
    "    inv=inv_ds.inv.shift(time=1)\n",
    "    w=wLevData.wap.sel(plev=70000,method='nearest').shift(time=1)\n",
    "    ushear=ushear_ds.ushear.shift(time=1)\n",
    "    \n",
    "    t2mTsAll=t2m[((t2m.time.dt.month>11) | (t2m.time.dt.month<2)) & (t2m.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    wsTsAll=ws[((ws.time.dt.month>11) | (ws.time.dt.month<2)) & (ws.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    rhTsAll=rh[((rh.time.dt.month>11) | (rh.time.dt.month<2)) & (rh.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    invTsAll=inv[((inv.time.dt.month>11) | (inv.time.dt.month<2)) & (inv.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    ushearTsAll=ushear[((ushear.time.dt.month>11) | (ushear.time.dt.month<2)) & (ushear.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    wTsAll=w[((w.time.dt.month>11) | (w.time.dt.month<2)) & (w.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    \n",
    "    \n",
    "    t1=t2mTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/t2mnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    t2mTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=wsTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/wsnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    wsTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=rhTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/rhnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    rhTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=invTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/invnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    invTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=ushearTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/ushearnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    ushearTsAll.values=t1.unstack()\n",
    "\n",
    "\n",
    "    t1=wTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/wnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    wTsAll.values=t1.unstack()\n",
    "    \n",
    "    t2mTsAll.values=t2mTsAll.values*mask\n",
    "    wsTsAll.values=wsTsAll.values*mask\n",
    "    rhTsAll.values=rhTsAll.values*mask\n",
    "    invTsAll.values=invTsAll.values*mask\n",
    "    ushearTsAll.values=ushearTsAll.values*mask\n",
    "    wTsAll.values=wTsAll.values*mask\n",
    "    \n",
    "    t2mTsAll.values=xr.where(np.isnan(t2mTsAll.values),  0.000000000001,t2mTsAll.values)\n",
    "    wsTsAll.values=xr.where(np.isnan(wsTsAll.values),  0.000000000001,wsTsAll.values)\n",
    "    rhTsAll.values=xr.where(np.isnan(rhTsAll.values),  0.000000000001,rhTsAll.values)\n",
    "    invTsAll.values=xr.where(np.isnan(invTsAll.values),  0.000000000001,invTsAll.values)\n",
    "    ushearTsAll.values=xr.where(np.isnan(ushearTsAll.values),  0.000000000001,ushearTsAll.values)\n",
    "    wTsAll.values=xr.where(np.isnan(wTsAll.values),  0.000000000001,wTsAll.values)\n",
    "    \n",
    "    t2mt=t2mTsAll.values\n",
    "    t2mt=t2mt[:,:,:,None]\n",
    "    t2mt.shape\n",
    "\n",
    "\n",
    "    wst=wsTsAll.values\n",
    "    wst=wst[:,:,:,None]\n",
    "    wst.shape\n",
    "\n",
    "    rht=rhTsAll.values\n",
    "    rht=rht[:,:,:,None]\n",
    "    rht.shape\n",
    "\n",
    "\n",
    "    invt=invTsAll.values\n",
    "    invt=invt[:,:,:,None]\n",
    "    invt.shape\n",
    "\n",
    "    wt=wTsAll.values\n",
    "    wt=wt[:,:,:,None]\n",
    "    wt.shape\n",
    "\n",
    "    usheart=ushearTsAll.values\n",
    "    usheart=usheart[:,:,:,None]\n",
    "    usheart.shape\n",
    "\n",
    "    aot=AO5DAll.values\n",
    "    aot=aot[:,:,:,None]\n",
    "    aot.shape\n",
    "\n",
    "    eut=EU5DAll.values\n",
    "    eut=eut[:,:,:,None]\n",
    "    eut.shape\n",
    "    \n",
    "    X=np.array([t2mt,rht,wst,invt,wt,usheart,aot,eut])\n",
    "    X.shape\n",
    "    \n",
    "    X_reshape = np.einsum('lkija->klija',X)\n",
    "    X_reshape.shape\n",
    "    \n",
    "    yLR=model.predict(X_reshape)\n",
    "    y_predLin_ds=xr.Dataset({'yLR': (('time'), yLR[:,0])}, coords={'time':t2mTsAll.time.values})\n",
    "    \n",
    "    dump(y_predLin_ds.yLR,'Modelplots_future/'+m+'_ssp126.joblib')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI-ESM1-2-LR\n"
     ]
    }
   ],
   "source": [
    "# Read Data \n",
    "#ModelList=['ACCESS-CM2','CanESM5','IITM-ESM','INM-CM4-8','INM-CM5-0',\n",
    " #          'IPSL-CM6A-LR','MIROC6','MRI-ESM2-0','MPI-ESM1-2-LR','MPI-ESM1-2-HR','EC-Earth3']\n",
    "#varList=['hurs','ta','tas','ua','uas','vas','wap','zg']\n",
    "ModelList=['MPI-ESM1-2-LR']\n",
    "gridlist=['gn']\n",
    "normList=['MpiEsm12Lr']\n",
    "\n",
    "for m,g,n in zip(ModelList,gridlist,normList) :\n",
    "    print(m)\n",
    "    folderString='/home/cccr/diptih/dipti/Data/ssp126/'+m+'/processed/'\n",
    "    #print(folderString)\n",
    "    #fName=folderString+'Regrid_'+v+'_day_'+m+'_ssp126_r1i1p1f1_gn_20150101-21001231.nc'\n",
    "    t2mData=xr.open_dataset(folderString+'Regrid_tas_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(t2mData)\n",
    "    rhData=xr.open_dataset(folderString+'Regrid_hurs_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(rhData)\n",
    "    v10Data=xr.open_dataset(folderString+'Regrid_vas_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(v10Data)\n",
    "    u10Data=xr.open_dataset(folderString+'Regrid_uas_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(u10Data)\n",
    "    tLevData=xr.open_dataset(folderString+'Regrid_ta_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(tLevData)\n",
    "    zLevData=xr.open_dataset(folderString+'Regrid_zg_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(zLevData)\n",
    "    wLevData=xr.open_dataset(folderString+'Regrid_wap_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(wLevData)\n",
    "    uLevData=xr.open_dataset(folderString+'Regrid_ua_day_'+m+'_ssp126_r1i1p1f1_'+g+'_20150101-21001231.nc')\n",
    "    #print(uLevData)\n",
    "    # Calculate wind speed and relative humidity inv  ushear\n",
    "    ws = ((v10Data.vas.values**2)+(u10Data.uas.values**2))**0.5\n",
    "    ws_ds = xr.Dataset({'ws': (('time','latitude','longitude'), ws)},\n",
    "                   coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "\n",
    "    rh_ds = xr.Dataset({'rh': (('time','latitude','longitude'), rhData.hurs/100.0)},\n",
    "                   coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "\n",
    "    #Calculate inv\n",
    "    inv=t2mData.tas.values-tLevData.ta.sel(plev=85000,method='nearest').values\n",
    "    inv_ds = xr.Dataset({'inv': (('time','latitude','longitude'), inv)}, coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "    inv_ds.attrs\n",
    "    inv_ds.attrs['units']='K'\n",
    "    inv_ds.attrs['long_name']='t2m - t850'\n",
    "\n",
    "    #u shear calculation\n",
    "    ushear=(uLevData.ua.sel(plev=85000,method='nearest').values-u10Data.uas.values)/(zLevData.zg.sel(plev=85000,method='nearest').values) \n",
    "    ushear_ds = xr.Dataset({'ushear': (('time','latitude','longitude'), ushear)}, coords={'time': v10Data.time,'latitude': v10Data.latitude,'longitude': v10Data.longitude})\n",
    "    ushear_ds.attrs['units']='s-1'\n",
    "    ushear_ds.attrs['long_name']='(u10 - u850)/z850'\n",
    "    \n",
    "\n",
    "\n",
    "    # AO data\n",
    "    AOData = xr.open_dataset(m+'-AOindex-NDJF-Daily-2015-2100.nc')\n",
    "    aoTS=AOData.AO\n",
    "        #datetimeindex = aoTS.indexes['time'].to_datetimeindex()\n",
    "    #datetimeindex\n",
    "    #aoTS['time'] = datetimeindex\n",
    "    Darray=np.zeros((AOData.time.shape[0],t2mData.latitude.shape[0], t2mData.longitude.shape[0]))\n",
    "    for t in range(aoTS.time.shape[0]) :\n",
    "        Darray[t,:,:]=np.full((t2mData.latitude.shape[0], t2mData.longitude.shape[0]), aoTS[t].values)\n",
    "    AOData=xr.Dataset({'AO': (('time','latitude','longitude'), Darray)},\n",
    "                  coords={'time': aoTS.time,'latitude': t2mData.latitude,'longitude': t2mData.longitude}) \n",
    "    # EU data\n",
    "    EUData = xr.open_dataset(m+'-EUindex-NDJF-Daily-2015-2100.nc')\n",
    "    EUData.EU\n",
    "    euTS=EUData.EU\n",
    "    #datetimeindex = euTS.indexes['time'].to_datetimeindex()\n",
    "    #datetimeindex\n",
    "    #euTS['time'] = datetimeindex\n",
    "    Darray=np.zeros((EUData.time.shape[0],t2mData.latitude.shape[0], t2mData.longitude.shape[0]))\n",
    "    for t in range(euTS.time.shape[0]) :\n",
    "        Darray[t,:,:]=np.full((t2mData.latitude.shape[0], t2mData.longitude.shape[0]), euTS[t].values)\n",
    "    EUData=xr.Dataset({'EU': (('time','latitude','longitude'), Darray)},\n",
    "                  coords={'time': euTS.time,'latitude': t2mData.latitude,'longitude': t2mData.longitude})\n",
    "    # create mask\n",
    "    oro = OroData.z.sel(latitude=slice(35,0),longitude=slice(50,100))\n",
    "    oro.values = OroData.z.sel(latitude=slice(35,0),longitude=slice(50,100)).values/9.81\n",
    "    oro.attrs\n",
    "    oro.attrs['units']='meter'\n",
    "    oro.attrs['long_name']='Orography'\n",
    "    oro.values[oro.values>500.1]=np.NaN\n",
    "    mask=oro.values/oro.values\n",
    "    #AO\n",
    "    AO5D=AOData.AO.rolling(time=5).mean()\n",
    "\n",
    "    AO5DAll=AO5D[((AO5D.time.dt.month>11) | (AO5D.time.dt.month<2)) & \n",
    "             (AO5D.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),\n",
    "                                           longitude=slice(50,100))\n",
    "\n",
    "    #EU\n",
    "    EU5D=EUData.EU.rolling(time=5).mean()\n",
    "\n",
    "    EU5DAll=EU5D[((EU5D.time.dt.month>11) | (EU5D.time.dt.month<2)) & \n",
    "             (EU5D.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),\n",
    "                                           longitude=slice(50,100))\n",
    "    \n",
    "    t1=AO5DAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/AO5Dnorm'+n+'.joblib') \n",
    "    norm = StandardScaler().fit(t1)\n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    AO5DAll.values=t1.unstack()\n",
    "\n",
    "    t1=EU5DAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/EU5Dnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    EU5DAll.values=t1.unstack()\n",
    "\n",
    "    AO5DAll.values=AO5DAll.values*mask\n",
    "    AO5DAll.values=xr.where(np.isnan(AO5DAll.values),  0.000000000001,AO5DAll.values)\n",
    "\n",
    "    EU5DAll.values=EU5DAll.values*mask\n",
    "    EU5DAll.values=xr.where(np.isnan(EU5DAll.values),  0.000000000001,EU5DAll.values)\n",
    "    \n",
    "    t2m=t2mData.tas.shift(time=1)\n",
    "    ws=ws_ds.ws.shift(time=1)\n",
    "    rh=rh_ds.rh.shift(time=1)\n",
    "    inv=inv_ds.inv.shift(time=1)\n",
    "    w=wLevData.wap.sel(plev=70000,method='nearest').shift(time=1)\n",
    "    ushear=ushear_ds.ushear.shift(time=1)\n",
    "    \n",
    "    t2mTsAll=t2m[((t2m.time.dt.month>11) | (t2m.time.dt.month<2)) & (t2m.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    wsTsAll=ws[((ws.time.dt.month>11) | (ws.time.dt.month<2)) & (ws.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    rhTsAll=rh[((rh.time.dt.month>11) | (rh.time.dt.month<2)) & (rh.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    invTsAll=inv[((inv.time.dt.month>11) | (inv.time.dt.month<2)) & (inv.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    ushearTsAll=ushear[((ushear.time.dt.month>11) | (ushear.time.dt.month<2)) & (ushear.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    wTsAll=w[((w.time.dt.month>11) | (w.time.dt.month<2)) & (w.time.dt.year<2101)].sel(time=slice('2015-1-1','2100-12-31'),latitude=slice(35,0),longitude=slice(50,100))\n",
    "    \n",
    "    \n",
    "    t1=t2mTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/t2mnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    t2mTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=wsTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/wsnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    wsTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=rhTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/rhnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    rhTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=invTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/invnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    invTsAll.values=t1.unstack()\n",
    "\n",
    "    t1=ushearTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/ushearnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    ushearTsAll.values=t1.unstack()\n",
    "\n",
    "\n",
    "    t1=wTsAll.stack(z=(\"latitude\", \"longitude\"))\n",
    "    # fit scaler on training data\n",
    "    norm   = load('../../March2021/'+m+'/wnorm'+n+'.joblib') \n",
    "    # transform training data\n",
    "    t1.values = norm.transform(t1)\n",
    "    wTsAll.values=t1.unstack()\n",
    "    \n",
    "    t2mTsAll.values=t2mTsAll.values*mask\n",
    "    wsTsAll.values=wsTsAll.values*mask\n",
    "    rhTsAll.values=rhTsAll.values*mask\n",
    "    invTsAll.values=invTsAll.values*mask\n",
    "    ushearTsAll.values=ushearTsAll.values*mask\n",
    "    wTsAll.values=wTsAll.values*mask\n",
    "    \n",
    "    t2mTsAll.values=xr.where(np.isnan(t2mTsAll.values),  0.000000000001,t2mTsAll.values)\n",
    "    wsTsAll.values=xr.where(np.isnan(wsTsAll.values),  0.000000000001,wsTsAll.values)\n",
    "    rhTsAll.values=xr.where(np.isnan(rhTsAll.values),  0.000000000001,rhTsAll.values)\n",
    "    invTsAll.values=xr.where(np.isnan(invTsAll.values),  0.000000000001,invTsAll.values)\n",
    "    ushearTsAll.values=xr.where(np.isnan(ushearTsAll.values),  0.000000000001,ushearTsAll.values)\n",
    "    wTsAll.values=xr.where(np.isnan(wTsAll.values),  0.000000000001,wTsAll.values)\n",
    "    \n",
    "    t2mt=t2mTsAll.values\n",
    "    t2mt=t2mt[:,:,:,None]\n",
    "    t2mt.shape\n",
    "\n",
    "\n",
    "    wst=wsTsAll.values\n",
    "    wst=wst[:,:,:,None]\n",
    "    wst.shape\n",
    "\n",
    "    rht=rhTsAll.values\n",
    "    rht=rht[:,:,:,None]\n",
    "    rht.shape\n",
    "\n",
    "\n",
    "    invt=invTsAll.values\n",
    "    invt=invt[:,:,:,None]\n",
    "    invt.shape\n",
    "\n",
    "    wt=wTsAll.values\n",
    "    wt=wt[:,:,:,None]\n",
    "    wt.shape\n",
    "\n",
    "    usheart=ushearTsAll.values\n",
    "    usheart=usheart[:,:,:,None]\n",
    "    usheart.shape\n",
    "\n",
    "    aot=AO5DAll.values\n",
    "    aot=aot[:,:,:,None]\n",
    "    aot.shape\n",
    "\n",
    "    eut=EU5DAll.values\n",
    "    eut=eut[:,:,:,None]\n",
    "    eut.shape\n",
    "    \n",
    "    X=np.array([t2mt,rht,wst,invt,wt,usheart,aot,eut])\n",
    "    X.shape\n",
    "    \n",
    "    X_reshape = np.einsum('lkija->klija',X)\n",
    "    X_reshape.shape\n",
    "    \n",
    "    yLR=model.predict(X_reshape)\n",
    "    y_predLin_ds=xr.Dataset({'yLR': (('time'), yLR[:,0])}, coords={'time':t2mTsAll.time.values})\n",
    "    \n",
    "    dump(y_predLin_ds.yLR,'Modelplots_future/'+m+'_ssp126.joblib')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
